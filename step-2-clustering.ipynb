{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T23:00:27.678127Z",
     "iopub.status.busy": "2023-02-20T23:00:27.677736Z",
     "iopub.status.idle": "2023-02-20T23:00:39.569017Z",
     "shell.execute_reply": "2023-02-20T23:00:39.567751Z",
     "shell.execute_reply.started": "2023-02-20T23:00:27.678096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "#import cupy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from annoy import AnnoyIndex\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "\n",
    "    \n",
    "#class CFG1:\n",
    "#    num_workers = 24\n",
    "#    model = \"model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/\"\n",
    "#    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "#    batch_size = 128\n",
    "#    top_n = 50\n",
    "#    seed = 42\n",
    "#    used_columns = 'title'\n",
    "#    max_length = 50\n",
    "#    mode = 'train'\n",
    "#    \n",
    "#class CFG2:\n",
    "#    num_workers = 24\n",
    "#    model = \"model/all-MiniLM-L6-v2-epochs-1-tuned/\"\n",
    "#    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "#    batch_size = 128\n",
    "#    top_n = 50\n",
    "#    seed = 42\n",
    "#    used_columns = 'title'\n",
    "#    max_length = 150\n",
    "#    mode = 'val'\n",
    "\n",
    "class CFG3:\n",
    "    num_workers = 24\n",
    "    model = \"model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    batch_size = 64\n",
    "    top_n = 50\n",
    "    seed = 42\n",
    "    used_columns = 'title'\n",
    "    max_length = 64\n",
    "    mode = 'val'\n",
    "    \n",
    "CFG_list = [CFG3]\n",
    "    \n",
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "\n",
    "def feature_engineering(topics,content):\n",
    "    \n",
    "    topics['title'].fillna(\"no title\", inplace = True)\n",
    "    content['title'].fillna(\"no title\", inplace = True)\n",
    "    topics['description'].fillna(\"no description\", inplace = True)\n",
    "    content['description'].fillna(\"no description\", inplace = True)\n",
    "    \n",
    "    content['text'].fillna(\"no text\", inplace = True)\n",
    "    content['license'].fillna(\"no license\", inplace = True)\n",
    "    content['kind'].fillna(\"no kind\", inplace = True)\n",
    "\n",
    "    topics['title'] =  topics['title'] + '. Language_' + topics['language'] + \". Description: \" + topics['description']\n",
    "    content['title'] =  content['title'] +  '. Language_' + content['language'] + \". Description: \" + content['description']\n",
    "    return topics,content\n",
    "\n",
    "def read_data(cfg):\n",
    "    topics = pd.read_csv('data/topics.csv')\n",
    "    #topics = topics[topics.category != 'source']\n",
    "    content = pd.read_csv('data/content.csv')\n",
    "    correlations = pd.read_csv('data/kfold_correlations.csv')\n",
    "    if cfg.mode == 'val':\n",
    "        correlations = correlations[correlations.fold == 0]\n",
    "        \n",
    "    topics = topics.merge(correlations, how = 'inner', left_on = 'id', right_on = 'topic_id')\n",
    "    # Fillna titles \n",
    "    #topics = preprocess(topics,['title','description'])\n",
    "    #content = preprocess(content,['title','description'])\n",
    "    topics,content = feature_engineering(topics,content)\n",
    "    \n",
    "    #topics['title'] =  topics['title'] + '. Language_' + topics['language'] + \" \" + topics['description']\n",
    "    #content['title'] =  content['title'] +  '. Language_' + content['language'] + \" \" + content['description']\n",
    "    \n",
    "    #topics['title'] =  topics['title'] + ' <|=t_sep=|> '  + topics['description'] + ' <|=t_sep=|> language ( ' + topics['language'] +' )'\n",
    "    #content['title'] =  content['title'] + ' <|=t_sep=|> '  + content['description'] + ' <|=t_sep=|> ' + content['text'] + ' <|=t_sep=|> ' + content['kind'] + ' <|=t_sep=|> language ( ' + content['language'] + ' )'\n",
    "\n",
    "    #topics['title'] =  topics['title'] +  \". Description: \" + topics['description'] + ' Language_' + topics['language']\n",
    "    #content['title'] =  content['title'] + \". Description: \" + content['description'] + ' Language_' + content['language']  + \". Kind: \"+content['kind'] \n",
    "    #best for now\n",
    "    #topics['title'] =  topics['title'] + '. Language_' + topics['language']\n",
    "    #content['title'] =  content['title'] + '. Language_' + content['language']\n",
    "    \n",
    "    \n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['title'].astype(str).apply(lambda x: len(x))\n",
    "    content['length'] = content['title'].astype(str).apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    content.sort_values('length', inplace = True)\n",
    "    \n",
    "    # Drop cols\n",
    "    topics.drop(['description', 'channel', 'category', 'level', 'parent', 'has_content', 'length'], axis = 1, inplace = True)\n",
    "    content.drop(['description', 'kind', 'text', 'copyright_holder', 'license', 'length'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Reset index\n",
    "    topics.reset_index(drop = True, inplace = True)\n",
    "    content.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"topics.shape: {topics.shape}\")\n",
    "    print(f\"content.shape: {content.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return topics, content, correlations\n",
    "\n",
    "# =========================================================================================\n",
    "# Prepare input, tokenize\n",
    "# =========================================================================================\n",
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        max_length = cfg.max_length,\n",
    "        truncation=True,\n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Unsupervised dataset\n",
    "# =========================================================================================\n",
    "class uns_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['title'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        return inputs\n",
    "    \n",
    "# =========================================================================================\n",
    "# Mean pooling class\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "# =========================================================================================\n",
    "# Unsupervised model\n",
    "# =========================================================================================\n",
    "class uns_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model)\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        self.pool = MeanPooling()\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        return feature\n",
    "    \n",
    "# =========================================================================================\n",
    "# Get embeddings\n",
    "# =========================================================================================\n",
    "def get_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, inputs in enumerate(tqdm(loader)):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds\n",
    "\n",
    "# =========================================================================================\n",
    "# Get the amount of positive classes based on the total\n",
    "# =========================================================================================\n",
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)\n",
    "\n",
    "# =========================================================================================\n",
    "# F2 Score \n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "# =========================================================================================\n",
    "# Build our training set\n",
    "# =========================================================================================\n",
    "def build_training_set(topics, content, cfg):\n",
    "    # Create lists for training\n",
    "    topics_ids = []\n",
    "    content_ids = []\n",
    "    title1 = []\n",
    "    title2 = []\n",
    "    targets = []\n",
    "    folds = []\n",
    "    # Iterate over each topic\n",
    "    for k in tqdm(range(len(topics))):\n",
    "        row = topics.iloc[k]\n",
    "        topics_id = row['id']\n",
    "        topics_title = row['title']\n",
    "        predictions = row['predictions'].split(' ')\n",
    "        ground_truth = row['content_ids'].split(' ')\n",
    "        fold = row['fold']\n",
    "        for pred in predictions:\n",
    "            content_title = content.loc[pred, 'title']\n",
    "            topics_ids.append(topics_id)\n",
    "            content_ids.append(pred)\n",
    "            title1.append(topics_title)\n",
    "            title2.append(content_title)\n",
    "            folds.append(fold)\n",
    "            # If pred is in ground truth, 1 else 0\n",
    "            if pred in ground_truth:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "    # Build training dataset\n",
    "    train = pd.DataFrame(\n",
    "        {'topics_ids': topics_ids, \n",
    "         'content_ids': content_ids, \n",
    "         'title1': title1, \n",
    "         'title2': title2, \n",
    "         'target': targets,\n",
    "         'fold' : folds}\n",
    "    )\n",
    "    # Release memory\n",
    "    del topics_ids, content_ids, title1, title2, targets\n",
    "    gc.collect()\n",
    "    return train\n",
    "    \n",
    "# =========================================================================================\n",
    "# Get neighbors\n",
    "# =========================================================================================\n",
    "\n",
    "def cv_split(train, n_folds, seed):\n",
    "    kfold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train)):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    return train\n",
    "\n",
    "def white_spaces(x):\n",
    "    return re.sub(' +', ' ', x)\n",
    "\n",
    "def preprocess(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(\"\")\n",
    "        #df[col] = df[col].str.strip('123.!? \\n\\t')\n",
    "        #df[col] = df[col].str[:100]\n",
    "    return df\n",
    "\n",
    "def get_neighbors(topics, content, cfg):\n",
    "    # Create topics dataset\n",
    "    topics_dataset = uns_dataset(topics, cfg)\n",
    "    # Create content dataset\n",
    "    content_dataset = uns_dataset(content, cfg)\n",
    "    # Create topics and content dataloaders\n",
    "    topics_loader = DataLoader(\n",
    "        topics_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    content_loader = DataLoader(\n",
    "        content_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "        )\n",
    "    # Create unsupervised model to extract embeddings\n",
    "    model = uns_model(cfg)\n",
    "    model.to(device)\n",
    "    # Predict topics\n",
    "    topics_embeds = get_embeddings(topics_loader, model, device)\n",
    "    content_embeds = get_embeddings(content_loader, model, device)\n",
    "    return topics_embeds,content_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_recall_calculator(CFG_list,top_k=50):\n",
    "    topics_embeds_all = []\n",
    "    content_embeds_all = []\n",
    "    for _idx, CFG in enumerate(CFG_list):\n",
    "        print(f'trying:{CFG.model}')\n",
    "        topics, content, correlations = read_data(CFG)\n",
    "        topics_embeds,content_embeds = get_neighbors(topics,content,CFG)\n",
    "        if len(CFG_list) > 1:\n",
    "            topics_embeds_all.append(topics_embeds)\n",
    "            content_embeds_all.append(content_embeds)\n",
    "    if len(CFG_list) > 1:\n",
    "        topics_embeds = np.concatenate(topics_embeds_all,axis=1)\n",
    "        content_embeds = np.concatenate(content_embeds_all,axis=1)\n",
    "    print(\"Embedding Shapes:\", topics_embeds.shape, content_embeds.shape)\n",
    "    topics.rename(columns=lambda x: \"topic_\" + x, inplace=True)\n",
    "    content.rename(columns=lambda x: \"content_\" + x, inplace=True)\n",
    "    \n",
    "    model = AnnoyIndex(topics_embeds.shape[1], 'angular')\n",
    "\n",
    "    for idx in tqdm(range(content_embeds.shape[0])):\n",
    "        model.add_item(idx, content_embeds[idx])\n",
    "    print('Training Annoy Model...')\n",
    "    model.build(300)\n",
    "    print('Annoy Model, Done.')\n",
    "    print(f'Finding Nearest {top_k} contents for every topic...')\n",
    "    dfs = []\n",
    "    for topic_idx in tqdm(range(topics_embeds.shape[0])):\n",
    "        content_idx = model.get_nns_by_vector(topics_embeds[topic_idx],n=top_k)\n",
    "        df_temp = content[content.index.isin(content_idx)]\n",
    "        df_temp['topic_id'] = list(topics[topics.index.isin([topic_idx])].topic_id)[0]\n",
    "        df_temp['topic_title'] = list(topics[topics.index.isin([topic_idx])].topic_title)[0]\n",
    "        dfs.append(df_temp)\n",
    "    candidates = pd.concat(dfs).reset_index(drop=True)\n",
    "    aa = candidates.groupby(['topic_id'])['content_id'].agg(list).reset_index()\n",
    "    aa['predictions'] = aa.content_id.apply(lambda x: ' '.join(x))\n",
    "    aa.drop('content_id',axis=1,inplace=True)\n",
    "    topics_test = aa.merge(correlations, how = 'inner', left_on = ['topic_id'], right_on = ['topic_id'])\n",
    "    pos_score = get_pos_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "    print('Validation df shape:',topics_test.shape)\n",
    "    print(f'Model:{CFG.model}')\n",
    "    print(f'Our max positive score is {pos_score}')\n",
    "\n",
    "    f_score = f2_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "    print(f'Our f2_score is {f_score}')\n",
    "    \n",
    "    return {'max_pos_score':pos_score,'f2_score':f_score,'model':CFG.model,'top_k':top_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying:model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/\n",
      " \n",
      "--------------------------------------------------\n",
      "topics.shape: (12304, 6)\n",
      "content.shape: (154047, 3)\n",
      "correlations.shape: (12304, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed8ec7e9f60402e8660a82727c1f9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558e72cb84d240d08f4909b0e4723cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shapes: (12304, 768) (154047, 768)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b43c8e466d410ba84adc103af46846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Annoy Model...\n",
      "Annoy Model, Done.\n",
      "Finding Nearest 50 contents for every topic...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661e254cc80b4fa6bc95d73ce7a2ad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation df shape: (12304, 4)\n",
      "Model:model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/\n",
      "Our max positive score is 0.79927\n",
      "Our f2_score is 0.2225\n"
     ]
    }
   ],
   "source": [
    "result = max_recall_calculator(CFG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_pos_score': 0.80108,\n",
       " 'f2_score': 0.2233,\n",
       " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/',\n",
       " 'top_k': 50}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Top 50\n",
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
    "{'max_pos_score': 0.41479, 'f2_score': 0.1004}\n",
    "\n",
    "{'max_pos_score': 0.41571,\n",
    " 'f2_score': 0.1005,\n",
    " 'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    " 'top_k': 50} #title only\n",
    " \n",
    " {'max_pos_score': 0.29129,\n",
    " 'f2_score': 0.0723,\n",
    " 'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    " 'top_k': 50} title + description + text + kind\n",
    " \n",
    " {'max_pos_score': 0.27954,\n",
    " 'f2_score': 0.0732,\n",
    " 'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    " 'top_k': 50} title + description + text + kind\n",
    " \n",
    " {'max_pos_score': 0.43875,\n",
    " 'f2_score': 0.1089,\n",
    " 'model': 'sentence-transformers/paraphrase-mpnet-base-v2',\n",
    " 'top_k': 50} title\n",
    " \n",
    " {'max_pos_score': 0.55819,\n",
    " 'f2_score': 0.1493,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} scheduler = 'constantlr'\n",
    " \n",
    "{'max_pos_score': 0.62448,\n",
    " 'f2_score': 0.1704,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title\n",
    "\n",
    "{'max_pos_score': 0.64079,\n",
    " 'f2_score': 0.1755,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language\n",
    " \n",
    "{'max_pos_score': 0.64155,\n",
    " 'f2_score': 0.1758,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_  model.max_seq_length = 64\n",
    " \n",
    " {'max_pos_score': 0.64434,\n",
    " 'f2_score': 0.1764,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_  model.max_seq_length = 64\n",
    " \n",
    " {'max_pos_score': 0.6887,\n",
    " 'f2_score': 0.1902,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_ +description model.max_seq_length = 64\n",
    " \n",
    " {'max_pos_score': 0.7026,\n",
    " 'f2_score': 0.1933,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    " \n",
    " {'max_pos_score': 0.79927,\n",
    " 'f2_score': 0.2227,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    " \n",
    " {'max_pos_score': 0.80108,\n",
    " 'f2_score': 0.2233,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/',\n",
    " 'top_k': 50}\n",
    " \n",
    " \n",
    " {'max_pos_score': 0.60485,\n",
    " 'f2_score': 0.1627,\n",
    " 'model': 'model/all-MiniLM-L6-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying:model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/\n",
      " \n",
      "--------------------------------------------------\n",
      "topics.shape: (12304, 6)\n",
      "content.shape: (154047, 3)\n",
      "correlations.shape: (12304, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3ed2cd67434195a356bef036492a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e882842d314953923e893862b50ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topics_embeds_all = []\n",
    "content_embeds_all = []\n",
    "for _idx, CFG in enumerate(CFG_list):\n",
    "    print(f'trying:{CFG.model}')\n",
    "    topics, content, correlations = read_data(CFG)\n",
    "    topics_embeds,content_embeds = get_neighbors(topics,content,CFG)\n",
    "    topics_embeds_all.append(topics_embeds)\n",
    "    content_embeds_all.append(content_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_embeds = np.concatenate(topics_embeds_all,axis=1)\n",
    "#content_embeds = np.concatenate(content_embeds_all,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12304, 768), (154047, 768))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_embeds.shape, content_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.rename(columns=lambda x: \"topic_\" + x, inplace=True)\n",
    "content.rename(columns=lambda x: \"content_\" + x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d779acafb20349c1bc97b3960433c8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 7s, sys: 7.5 s, total: 51min 15s\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "model = AnnoyIndex(topics_embeds.shape[1], 'angular')\n",
    "\n",
    "for idx in tqdm(range(content_embeds.shape[0])):\n",
    "    model.add_item(idx, content_embeds[idx])\n",
    "    \n",
    "model.build(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7211be0870449acaccc339342c93e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for topic_idx in tqdm(range(topics_embeds.shape[0])):\n",
    "    content_idx = model.get_nns_by_vector(topics_embeds[topic_idx],n=50)\n",
    "    df_temp = content[content.index.isin(content_idx)]\n",
    "    df_temp['topic_id'] = list(topics[topics.index.isin([topic_idx])].topic_id)[0]\n",
    "    df_temp['topic_title'] = list(topics[topics.index.isin([topic_idx])].topic_title)[0]\n",
    "    #df_temp['topic_language'] = list(topics[topics.index.isin([topic_idx])].topic_language)[0]\n",
    "    #df_temp['is_language'] = (df_temp['topic_language'] == df_temp['content_language'])\n",
    "    #df_temp = df_temp[(df_temp.is_language==True) | (df_temp.content_language=='en') | (df_temp.content_language=='es') | (df_temp.content_language=='fr') | (df_temp.content_language=='ar')]\n",
    "    if df_temp.shape[0] == 0:\n",
    "        break\n",
    "    #df_temp = df_temp.head(50)\n",
    "    #display(df_temp)\n",
    "    dfs.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = candidates.groupby(['topic_id'])['content_id'].agg(list).reset_index()\n",
    "aa['predictions'] = aa.content_id.apply(lambda x: ' '.join(x))\n",
    "aa.drop('content_id',axis=1,inplace=True)\n",
    "topics_test = aa.merge(correlations, how = 'inner', left_on = ['topic_id'], right_on = ['topic_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our max positive score is 0.80299\n",
      "Our f2_score is 0.2237\n"
     ]
    }
   ],
   "source": [
    "pos_score = get_pos_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our max positive score is {pos_score}')\n",
    "\n",
    "f_score = f2_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our f2_score is {f_score}')\n",
    "\n",
    "#Validation\n",
    "#Our max positive score is 0.78403\n",
    "#Our f2_score is 0.2239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Our max positive score is 0.80093\n",
    "Our f2_score is 0.2232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>predictions</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0feaaa5dc39d c_82eaf550b23b c_0262b16c8ecc c...</td>\n",
       "      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_14860bbee722 c_a72612bc23cb c_5b58b9ccaff5 c...</td>\n",
       "      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_fbb55ec5bb93 c_186fc761585b c_c4b6db8b5c7d c...</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_6cd02c88f340 c_beddc68789b7 c_cde9544b589e c...</td>\n",
       "      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0008768bdee6</td>\n",
       "      <td>c_6485703d86a9 c_9e801e3f512e c_e496ba917d34 c...</td>\n",
       "      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61512</th>\n",
       "      <td>t_fff830472691</td>\n",
       "      <td>c_28742eece061 c_ec5a875e22ab c_9f5618066a2a c...</td>\n",
       "      <td>c_61fb63326e5d c_8f224e321c87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61513</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>c_a86539ee631f c_18529667fd21 c_90cc64d55d46 c...</td>\n",
       "      <td>c_026db653a269 c_0fb048a6412c c_20de77522603 c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61514</th>\n",
       "      <td>t_fffbe1d5d43c</td>\n",
       "      <td>c_f9512ad7d2c0 c_ef287a34941d c_2b3c03aeb915 c...</td>\n",
       "      <td>c_46f852a49c08 c_6659207b25d5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61515</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_f15928e0f771 c_47a8fdc3f590 c_883c53c22054 c...</td>\n",
       "      <td>c_cece166bad6a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61516</th>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>c_1c52c94e8474 c_e67a605edd1c c_d43845d68c27 c...</td>\n",
       "      <td>c_92b8fad372ee</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61517 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic_id                                        predictions  \\\n",
       "0      t_00004da3a1b2  c_0feaaa5dc39d c_82eaf550b23b c_0262b16c8ecc c...   \n",
       "1      t_00068291e9a4  c_14860bbee722 c_a72612bc23cb c_5b58b9ccaff5 c...   \n",
       "2      t_00069b63a70a  c_fbb55ec5bb93 c_186fc761585b c_c4b6db8b5c7d c...   \n",
       "3      t_0006d41a73a8  c_6cd02c88f340 c_beddc68789b7 c_cde9544b589e c...   \n",
       "4      t_0008768bdee6  c_6485703d86a9 c_9e801e3f512e c_e496ba917d34 c...   \n",
       "...               ...                                                ...   \n",
       "61512  t_fff830472691  c_28742eece061 c_ec5a875e22ab c_9f5618066a2a c...   \n",
       "61513  t_fff9e5407d13  c_a86539ee631f c_18529667fd21 c_90cc64d55d46 c...   \n",
       "61514  t_fffbe1d5d43c  c_f9512ad7d2c0 c_ef287a34941d c_2b3c03aeb915 c...   \n",
       "61515  t_fffe14f1be1e  c_f15928e0f771 c_47a8fdc3f590 c_883c53c22054 c...   \n",
       "61516  t_fffe811a6da9  c_1c52c94e8474 c_e67a605edd1c c_d43845d68c27 c...   \n",
       "\n",
       "                                             content_ids  fold  \n",
       "0      c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...     1  \n",
       "1      c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...     1  \n",
       "2                                         c_11a1dc0bfb99     4  \n",
       "3      c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...     2  \n",
       "4           c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4     0  \n",
       "...                                                  ...   ...  \n",
       "61512                      c_61fb63326e5d c_8f224e321c87     1  \n",
       "61513  c_026db653a269 c_0fb048a6412c c_20de77522603 c...     4  \n",
       "61514                      c_46f852a49c08 c_6659207b25d5     2  \n",
       "61515                                     c_cece166bad6a     2  \n",
       "61516                                     c_92b8fad372ee     3  \n",
       "\n",
       "[61517 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Train Data for Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_test['predictions'] = topics_test.predictions.apply(lambda x: x.split(' '))\n",
    "topics_test['content_ids'] = topics_test.content_ids.apply(lambda x: x.split(' '))\n",
    "gt = topics_test[['topic_id','content_ids','fold']].explode('content_ids')\n",
    "preds = topics_test[['topic_id','predictions','fold']].explode('predictions')\n",
    "candidates_df = preds.merge(gt[['topic_id','content_ids']],how='left',left_on=['topic_id','predictions'], right_on=['topic_id','content_ids'])\n",
    "candidates_df.loc[candidates_df.content_ids.isnull(),'target'] = 0\n",
    "candidates_df['target'] = candidates_df.target.fillna(1)\n",
    "candidates_df.drop('content_ids',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61517"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df.topic_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = candidates_df.rename(columns={'predictions':'content_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = candidates_df.merge(topics[['topic_id','topic_title']],on='topic_id')\n",
    "candidates_df = candidates_df.merge(content[['content_id','content_title']],on='content_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075850, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>content_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Откриването на резисторите. Language_bg. Descr...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_09ad67f245fc</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Електрични заряди и електрично поле. Language_...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_261fb7043ad1</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Електричен ток и електрично напрежение. Langua...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_2b1b6dfd096b</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Електрично поле. Language_bg. Description: no ...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_3a1f5ae9f991</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Вериги с кондензатори. Language_bg. Descriptio...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075845</th>\n",
       "      <td>t_fea53cc2a5bb</td>\n",
       "      <td>c_c4c2b22ec356</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Suma y Resta de Fracciones. Language_es. Descr...</td>\n",
       "      <td>Calcula Expresiones con Números Mixtos. Langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075846</th>\n",
       "      <td>t_ff0a0977e1fc</td>\n",
       "      <td>c_b49da9b18f9e</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>يتعرف التمثيل البياني للدوال المثلثية (جـا س ،...</td>\n",
       "      <td>يتعرف التمثيل البياني للدوال المثلثية (جـا س ،...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075847</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>c_20de77522603</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NA_U06 - El periódico. Language_es. Descriptio...</td>\n",
       "      <td>Resumen: El periódico. Language_es. Descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075848</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>c_d64037a72376</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NA_U06 - El periódico. Language_es. Descriptio...</td>\n",
       "      <td>Introducción: El periódico. Language_es. Descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075849</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>c_5a80e03b571a</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NA_U06 - El periódico. Language_es. Descriptio...</td>\n",
       "      <td>Ponte a prueba: El periódico. Language_es. Des...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3075850 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic_id      content_id  fold  target  \\\n",
       "0        t_00004da3a1b2  c_0feaaa5dc39d     1     0.0   \n",
       "1        t_09ad67f245fc  c_0feaaa5dc39d     1     0.0   \n",
       "2        t_261fb7043ad1  c_0feaaa5dc39d     3     0.0   \n",
       "3        t_2b1b6dfd096b  c_0feaaa5dc39d     0     0.0   \n",
       "4        t_3a1f5ae9f991  c_0feaaa5dc39d     0     0.0   \n",
       "...                 ...             ...   ...     ...   \n",
       "3075845  t_fea53cc2a5bb  c_c4c2b22ec356     2     1.0   \n",
       "3075846  t_ff0a0977e1fc  c_b49da9b18f9e     3     1.0   \n",
       "3075847  t_fff9e5407d13  c_20de77522603     4     1.0   \n",
       "3075848  t_fff9e5407d13  c_d64037a72376     4     1.0   \n",
       "3075849  t_fff9e5407d13  c_5a80e03b571a     4     1.0   \n",
       "\n",
       "                                               topic_title  \\\n",
       "0        Откриването на резисторите. Language_bg. Descr...   \n",
       "1        Електрични заряди и електрично поле. Language_...   \n",
       "2        Електричен ток и електрично напрежение. Langua...   \n",
       "3        Електрично поле. Language_bg. Description: no ...   \n",
       "4        Вериги с кондензатори. Language_bg. Descriptio...   \n",
       "...                                                    ...   \n",
       "3075845  Suma y Resta de Fracciones. Language_es. Descr...   \n",
       "3075846  يتعرف التمثيل البياني للدوال المثلثية (جـا س ،...   \n",
       "3075847  NA_U06 - El periódico. Language_es. Descriptio...   \n",
       "3075848  NA_U06 - El periódico. Language_es. Descriptio...   \n",
       "3075849  NA_U06 - El periódico. Language_es. Descriptio...   \n",
       "\n",
       "                                             content_title  \n",
       "0        Успоредно свързани резистори. Language_bg. Des...  \n",
       "1        Успоредно свързани резистори. Language_bg. Des...  \n",
       "2        Успоредно свързани резистори. Language_bg. Des...  \n",
       "3        Успоредно свързани резистори. Language_bg. Des...  \n",
       "4        Успоредно свързани резистори. Language_bg. Des...  \n",
       "...                                                    ...  \n",
       "3075845  Calcula Expresiones con Números Mixtos. Langua...  \n",
       "3075846  يتعرف التمثيل البياني للدوال المثلثية (جـا س ،...  \n",
       "3075847  Resumen: El periódico. Language_es. Descriptio...  \n",
       "3075848  Introducción: El periódico. Language_es. Descr...  \n",
       "3075849  Ponte a prueba: El periódico. Language_es. Des...  \n",
       "\n",
       "[3075850 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('data/train_top50_fold0_cv_with_groundtruth_final_72044.csv')#.fold.unique()#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df.columns = ['topics_ids','content_ids','fold','target','title1','title2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df[['topics_ids', 'content_ids', 'title1', 'title2', 'target', 'fold']].to_parquet('data/candidates_50_train_79927.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL DATA\n",
    "------------------------------------------------------------------\n",
    "#### NO TUNE\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2\n",
    "Our max positive score is 0.41649\n",
    "Our f2_score is 0.1007\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sentence-embedding-models/paraphrase-MiniLM-L12-v2\n",
    "Our max positive score is 0.44421\n",
    "Our f2_score is 0.1099\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sentence-embedding-models/paraphrase-mpnet-base-v2\n",
    "Our max positive score is 0.45422\n",
    "Our f2_score is 0.1133\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2\n",
    "Our max positive score is 0.42578\n",
    "Our f2_score is 0.1033\n",
    "\n",
    "---------------\n",
    "TOP 50\n",
    "/kaggle/input/paraphrasemultilingualmpnetbasev2/all-MiniLM-L6-v2\n",
    "Our max positive score is 0.47988\n",
    "Our f2_score is 0.1216\n",
    "\n",
    "------------------------------------------------------------------\n",
    "#### TUNED\n",
    "----------------\n",
    "TOP 50\n",
    "'/kaggle/input/paraphrase-multilingual-mpnet-base-v2-tuned/paraphrase-multilingual-mpnet-base-v2-exp_fold0_epochs8'\n",
    "Our max positive score is 0.68706\n",
    "Our f2_score is 0.1902\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "'/kaggle/input/stage-1-tuned/paraphrase-multilingual-mpnet-base-v2-tuned' ##15 epoch\n",
    "Our max positive score is 0.72044\n",
    "Our f2_score is 0.201\n",
    "\n",
    "---------------\n",
    "TOP 50\n",
    "'/kaggle/input/all-minilm-l6-v2-tuned/all-MiniLM-L6-v2_fold0_epochs20/all-MiniLM-L6-v2_fold0_epochs20'\n",
    "Our max positive score is 0.62932\n",
    "Our f2_score is 0.1713\n",
    "\n",
    "---------------\n",
    "TOP 50\n",
    "'/kaggle/input/all-minilm-l6-v2-tuned/all-MiniLM-L6-v2_fold0_epochs8/all-MiniLM-L6-v2_fold0_epochs8'\n",
    "Our max positive score is 0.59703\n",
    "Our f2_score is 0.1607"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T20:20:01.244452Z",
     "iopub.status.busy": "2023-02-18T20:20:01.244038Z",
     "iopub.status.idle": "2023-02-18T20:21:04.060718Z",
     "shell.execute_reply": "2023-02-18T20:21:04.059568Z",
     "shell.execute_reply.started": "2023-02-18T20:20:01.244415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fd1ae060bc44848dfe46e34056eb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training set has 3119827 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics_ids</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_8a2c8da77d0c</td>\n",
       "      <td></td>\n",
       "      <td>Agenda</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_3f51421a7c85</td>\n",
       "      <td></td>\n",
       "      <td>ABCD</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_db7818729577</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_eb7d5e2e1744</td>\n",
       "      <td></td>\n",
       "      <td>Simon</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_60dd2fc8a271</td>\n",
       "      <td></td>\n",
       "      <td>Ihab</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topics_ids     content_ids title1  title2  target  fold\n",
       "0  t_3d9ad9931021  c_8a2c8da77d0c         Agenda       1     3\n",
       "1  t_3d9ad9931021  c_3f51421a7c85           ABCD       0     3\n",
       "2  t_3d9ad9931021  c_db7818729577                      0     3\n",
       "3  t_3d9ad9931021  c_eb7d5e2e1744          Simon       0     3\n",
       "4  t_3d9ad9931021  c_60dd2fc8a271           Ihab       0     3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build training set\n",
    "full_correlations = pd.read_csv('/kaggle/input/all-minilm-l6-v2-tuned/kfold_correlations.csv')\n",
    "topics_full = topics.merge(full_correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "topics_full['predictions'] = topics_full.apply(lambda x: ' '.join(list(set(x.predictions.split(' ') + x.content_ids.split(' ')))) \\\n",
    "                                               if x.fold != 0 else x.predictions, axis = 1)\n",
    "train = build_training_set(topics_full, content, CFG)\n",
    "print(f'Our training set has {len(train)} rows')\n",
    "# Save train set to disk to train on another notebook\n",
    "train.to_csv(f'train_top{CFG.top_n}_fold0_cv_with_groundtruth_final_72044.csv', index = False)\n",
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

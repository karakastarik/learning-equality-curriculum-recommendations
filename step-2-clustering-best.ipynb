{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-20T23:00:27.678127Z",
     "iopub.status.busy": "2023-02-20T23:00:27.677736Z",
     "iopub.status.idle": "2023-02-20T23:00:39.569017Z",
     "shell.execute_reply": "2023-02-20T23:00:39.567751Z",
     "shell.execute_reply.started": "2023-02-20T23:00:27.678096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================================================================================\n",
    "# Libraries\n",
    "# =========================================================================================\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "#import cupy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import string\n",
    "from annoy import AnnoyIndex\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# =========================================================================================\n",
    "# Configurations\n",
    "# =========================================================================================\n",
    "\n",
    "    \n",
    "#class CFG1:\n",
    "#    num_workers = 24\n",
    "#    model = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "#    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "#    batch_size = 128\n",
    "#    top_n = 50\n",
    "#    seed = 42\n",
    "#    max_length = 50\n",
    "#    mode = 'val'\n",
    "\n",
    "class CFG2:\n",
    "    num_workers = 24\n",
    "    model = \"model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-30-seq-50-tuned/\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    batch_size = 128\n",
    "    top_n = 50\n",
    "    seed = 42\n",
    "    used_columns = 'title'\n",
    "    max_length = 50\n",
    "    mode = 'all'\n",
    "\n",
    "#class CFG3:\n",
    "#    num_workers = 24\n",
    "#    model = \"model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/\"\n",
    "#    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "#    batch_size = 128\n",
    "#    top_n = 50\n",
    "#    seed = 42\n",
    "#    used_columns = 'title'\n",
    "#    max_length = 128\n",
    "#    mode = 'train'\n",
    "    \n",
    "CFG_list = [CFG2]\n",
    "    \n",
    "# =========================================================================================\n",
    "# Data Loading\n",
    "# =========================================================================================\n",
    "def feature_engineering(topics,content):\n",
    "    #topics['description'] = topics['description'].str.replace('\\n\\n',\"\")\n",
    "    #content['description'] = content['description'].str.replace('\\n\\n',\"\")\n",
    "    #topics['description'] = topics['description'].str.replace('\\n',\"\")\n",
    "    #content['description'] = content['description'].str.replace('\\n',\"\")\n",
    "    #\n",
    "    #\n",
    "    #topics['title'] = topics['title'].str.replace('\\n\\n',\"\")\n",
    "    #content['title'] = content['title'].str.replace('\\n\\n',\"\")\n",
    "    #topics['title'] = topics['title'].str.replace('\\n',\"\")\n",
    "    #content['title'] = content['title'].str.replace('\\n',\"\")\n",
    "\n",
    "    content['description'] = content['description'].fillna(content['text'])\n",
    "    content['description'] = content['description'].fillna(content['kind'])\n",
    "    \n",
    "    topics['description'] = topics['description'].fillna(topics['category'])\n",
    "    \n",
    "    topics['title'].fillna(\"no title\", inplace = True)\n",
    "    content['title'].fillna(\"no title\", inplace = True)\n",
    "    topics['description'].fillna(\"no description\", inplace = True)\n",
    "    content['description'].fillna(\"no description\", inplace = True)\n",
    "    \n",
    "    content['text'].fillna(\"no text\", inplace = True)\n",
    "    content['license'].fillna(\"no license\", inplace = True)\n",
    "    content['kind'].fillna(\"no kind\", inplace = True)\n",
    "\n",
    "    topics['title'] =  topics['title'] + '. Language_' + topics['language'] + \". Description: \" + topics['description']\n",
    "    content['title'] =  content['title'] +  '. Language_' + content['language'] + \". Description: \" + content['description']\n",
    "    return topics,content\n",
    "\n",
    "def read_data(cfg):\n",
    "    topics = pd.read_csv('data/topics.csv')\n",
    "    #topics = topics[topics.category != 'source']\n",
    "    content = pd.read_csv('data/content.csv')\n",
    "    correlations = pd.read_csv('data/kfold_correlations.csv')\n",
    "    if cfg.mode == 'val':\n",
    "        correlations = correlations[correlations.fold == 0]\n",
    "    if cfg.mode == 'train':\n",
    "        correlations = correlations[correlations.fold != 0]\n",
    "        \n",
    "    topics = topics.merge(correlations, how = 'inner', left_on = 'id', right_on = 'topic_id')\n",
    "    \n",
    "    #FE\n",
    "    topics,content = feature_engineering(topics,content)\n",
    "    \n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['title'].astype(str).apply(lambda x: len(x))\n",
    "    content['length'] = content['title'].astype(str).apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    content.sort_values('length', inplace = True)\n",
    "    \n",
    "    # Drop cols\n",
    "    topics.drop(['description', 'channel', 'category', 'level', 'parent', 'has_content', 'length'], axis = 1, inplace = True)\n",
    "    content.drop(['description', 'kind', 'text', 'copyright_holder', 'license', 'length'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Reset index\n",
    "    topics.reset_index(drop = True, inplace = True)\n",
    "    content.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    print(' ')\n",
    "    print('-' * 50)\n",
    "    print(f\"topics.shape: {topics.shape}\")\n",
    "    print(f\"content.shape: {content.shape}\")\n",
    "    print(f\"correlations.shape: {correlations.shape}\")\n",
    "    return topics, content, correlations\n",
    "\n",
    "# =========================================================================================\n",
    "# Prepare input, tokenize\n",
    "# =========================================================================================\n",
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        max_length = cfg.max_length,\n",
    "        truncation=True,\n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs\n",
    "\n",
    "# =========================================================================================\n",
    "# Unsupervised dataset\n",
    "# =========================================================================================\n",
    "class uns_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['title'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        return inputs\n",
    "    \n",
    "# =========================================================================================\n",
    "# Mean pooling class\n",
    "# =========================================================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "# =========================================================================================\n",
    "# Unsupervised model\n",
    "# =========================================================================================\n",
    "class uns_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model)\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        self.pool = MeanPooling()\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        return feature\n",
    "    \n",
    "# =========================================================================================\n",
    "# Get embeddings\n",
    "# =========================================================================================\n",
    "def get_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, inputs in enumerate(tqdm(loader)):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds\n",
    "\n",
    "# =========================================================================================\n",
    "# Get the amount of positive classes based on the total\n",
    "# =========================================================================================\n",
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)\n",
    "\n",
    "# =========================================================================================\n",
    "# F2 Score \n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "# =========================================================================================\n",
    "# Build our training set\n",
    "# =========================================================================================\n",
    "def build_training_set(topics, content, cfg):\n",
    "    # Create lists for training\n",
    "    topics_ids = []\n",
    "    content_ids = []\n",
    "    title1 = []\n",
    "    title2 = []\n",
    "    targets = []\n",
    "    folds = []\n",
    "    # Iterate over each topic\n",
    "    for k in tqdm(range(len(topics))):\n",
    "        row = topics.iloc[k]\n",
    "        topics_id = row['id']\n",
    "        topics_title = row['title']\n",
    "        predictions = row['predictions'].split(' ')\n",
    "        ground_truth = row['content_ids'].split(' ')\n",
    "        fold = row['fold']\n",
    "        for pred in predictions:\n",
    "            content_title = content.loc[pred, 'title']\n",
    "            topics_ids.append(topics_id)\n",
    "            content_ids.append(pred)\n",
    "            title1.append(topics_title)\n",
    "            title2.append(content_title)\n",
    "            folds.append(fold)\n",
    "            # If pred is in ground truth, 1 else 0\n",
    "            if pred in ground_truth:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "    # Build training dataset\n",
    "    train = pd.DataFrame(\n",
    "        {'topics_ids': topics_ids, \n",
    "         'content_ids': content_ids, \n",
    "         'title1': title1, \n",
    "         'title2': title2, \n",
    "         'target': targets,\n",
    "         'fold' : folds}\n",
    "    )\n",
    "    # Release memory\n",
    "    del topics_ids, content_ids, title1, title2, targets\n",
    "    gc.collect()\n",
    "    return train\n",
    "    \n",
    "# =========================================================================================\n",
    "# Get neighbors\n",
    "# =========================================================================================\n",
    "\n",
    "def cv_split(train, n_folds, seed):\n",
    "    kfold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    for num, (train_index, val_index) in enumerate(kfold.split(train)):\n",
    "        train.loc[val_index, 'fold'] = int(num)\n",
    "    train['fold'] = train['fold'].astype(int)\n",
    "    return train\n",
    "\n",
    "def white_spaces(x):\n",
    "    return re.sub(' +', ' ', x)\n",
    "\n",
    "def preprocess(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(\"\")\n",
    "        #df[col] = df[col].str.strip('123.!? \\n\\t')\n",
    "        #df[col] = df[col].str[:100]\n",
    "    return df\n",
    "\n",
    "def get_neighbors(topics, content, cfg):\n",
    "    # Create topics dataset\n",
    "    topics_dataset = uns_dataset(topics, cfg)\n",
    "    # Create content dataset\n",
    "    content_dataset = uns_dataset(content, cfg)\n",
    "    # Create topics and content dataloaders\n",
    "    topics_loader = DataLoader(\n",
    "        topics_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    content_loader = DataLoader(\n",
    "        content_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "        )\n",
    "    # Create unsupervised model to extract embeddings\n",
    "    model = uns_model(cfg)\n",
    "    model.to(device)\n",
    "    # Predict topics\n",
    "    topics_embeds = get_embeddings(topics_loader, model, device)\n",
    "    content_embeds = get_embeddings(content_loader, model, device)\n",
    "    return topics_embeds,content_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_recall_calculator(CFG_list,top_k=50):\n",
    "    topics_embeds_all = []\n",
    "    content_embeds_all = []\n",
    "    for _idx, CFG in enumerate(CFG_list):\n",
    "        print(f'trying:{CFG.model}')\n",
    "        topics, content, correlations = read_data(CFG)\n",
    "        topics_embeds,content_embeds = get_neighbors(topics,content,CFG)\n",
    "        if len(CFG_list) > 1:\n",
    "            topics_embeds_all.append(topics_embeds)\n",
    "            content_embeds_all.append(content_embeds)\n",
    "    if len(CFG_list) > 1:\n",
    "        topics_embeds = np.concatenate(topics_embeds_all,axis=1)\n",
    "        content_embeds = np.concatenate(content_embeds_all,axis=1)\n",
    "    print(\"Embedding Shapes:\", topics_embeds.shape, content_embeds.shape)\n",
    "    topics.rename(columns=lambda x: \"topic_\" + x, inplace=True)\n",
    "    content.rename(columns=lambda x: \"content_\" + x, inplace=True)\n",
    "    \n",
    "    model = AnnoyIndex(topics_embeds.shape[1], 'angular')\n",
    "\n",
    "    for idx in tqdm(range(content_embeds.shape[0])):\n",
    "        model.add_item(idx, content_embeds[idx])\n",
    "    print('Training Annoy Model...')\n",
    "    model.build(300)\n",
    "    print('Annoy Model, Done.')\n",
    "    print(f'Finding Nearest {top_k} contents for every topic...')\n",
    "    dfs = []\n",
    "    for topic_idx in tqdm(range(topics_embeds.shape[0])):\n",
    "        content_idx = model.get_nns_by_vector(topics_embeds[topic_idx],n=top_k)\n",
    "        df_temp = content[content.index.isin(content_idx)]\n",
    "        df_temp['topic_id'] = list(topics[topics.index.isin([topic_idx])].topic_id)[0]\n",
    "        df_temp['topic_title'] = list(topics[topics.index.isin([topic_idx])].topic_title)[0]\n",
    "        dfs.append(df_temp)\n",
    "    candidates = pd.concat(dfs).reset_index(drop=True)\n",
    "    aa = candidates.groupby(['topic_id'])['content_id'].agg(list).reset_index()\n",
    "    aa['predictions'] = aa.content_id.apply(lambda x: ' '.join(x))\n",
    "    aa.drop('content_id',axis=1,inplace=True)\n",
    "    topics_test = aa.merge(correlations, how = 'inner', left_on = ['topic_id'], right_on = ['topic_id'])\n",
    "    pos_score = get_pos_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "    print('Validation df shape:',topics_test.shape)\n",
    "    print(f'Model:{CFG.model}')\n",
    "    print(f'Our max positive score is {pos_score}')\n",
    "\n",
    "    f_score = f2_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "    print(f'Our f2_score is {f_score}')\n",
    "    \n",
    "    return {'max_pos_score':pos_score,'f2_score':f_score,'model':CFG.model,'top_k':top_k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying:model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-30-seq-50-tuned/\n",
      " \n",
      "--------------------------------------------------\n",
      "topics.shape: (12304, 6)\n",
      "content.shape: (154047, 3)\n",
      "correlations.shape: (12304, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9451c73c6eec4f5c8faaeb3f791735de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca6c9cfe7ee4b7b830388d61a4773af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shapes: (12304, 768) (154047, 768)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395630ac6de24b3baa158125812fc133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Annoy Model...\n",
      "Annoy Model, Done.\n",
      "Finding Nearest 50 contents for every topic...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23497a5a702943dbb230c11b72da5992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation df shape: (12304, 4)\n",
      "Model:model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-30-seq-50-tuned/\n",
      "Our max positive score is 0.84682\n",
      "Our f2_score is 0.2343\n"
     ]
    }
   ],
   "source": [
    "result = max_recall_calculator(CFG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_pos_score': 0.84682,\n",
       " 'f2_score': 0.2343,\n",
       " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-30-seq-50-tuned/',\n",
       " 'top_k': 50}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Kaggle like split\n",
    "##valid\n",
    "{'max_pos_score': 0.54845,\n",
    " 'f2_score': 0.1443,\n",
    " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-1-seq-50-tuned/',\n",
    " 'top_k': 50}\n",
    " \n",
    " ## train\n",
    " Model:model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-1-seq-50-tuned/\n",
    "Our max positive score is 0.74245\n",
    "Our f2_score is 0.2075"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Top 50\n",
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
    "{'max_pos_score': 0.41479, 'f2_score': 0.1004}\n",
    "\n",
    "{'max_pos_score': 0.41571,\n",
    " 'f2_score': 0.1005,\n",
    " 'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    " 'top_k': 50} #title only\n",
    " \n",
    " {'max_pos_score': 0.29129,\n",
    " 'f2_score': 0.0723,\n",
    " 'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    " 'top_k': 50} title + description + text + kind\n",
    " \n",
    " {'max_pos_score': 0.27954,\n",
    " 'f2_score': 0.0732,\n",
    " 'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
    " 'top_k': 50} title + description + text + kind\n",
    " \n",
    " {'max_pos_score': 0.43875,\n",
    " 'f2_score': 0.1089,\n",
    " 'model': 'sentence-transformers/paraphrase-mpnet-base-v2',\n",
    " 'top_k': 50} title\n",
    " \n",
    " {'max_pos_score': 0.55819,\n",
    " 'f2_score': 0.1493,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} scheduler = 'constantlr'\n",
    " \n",
    "{'max_pos_score': 0.62448,\n",
    " 'f2_score': 0.1704,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title\n",
    "\n",
    "{'max_pos_score': 0.64079,\n",
    " 'f2_score': 0.1755,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language\n",
    " \n",
    "{'max_pos_score': 0.64155,\n",
    " 'f2_score': 0.1758,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_  model.max_seq_length = 64\n",
    " \n",
    " {'max_pos_score': 0.64434,\n",
    " 'f2_score': 0.1764,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_  model.max_seq_length = 64\n",
    " \n",
    " {'max_pos_score': 0.6887,\n",
    " 'f2_score': 0.1902,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_ +description model.max_seq_length = 64\n",
    " \n",
    " {'max_pos_score': 0.7026,\n",
    " 'f2_score': 0.1933,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-1-tuned/',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    " \n",
    " {'max_pos_score': 0.79927,\n",
    " 'f2_score': 0.2227,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    " \n",
    " {'max_pos_score': 0.80108,\n",
    " 'f2_score': 0.2233,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    " \n",
    " {'max_pos_score': 0.35773,\n",
    " 'f2_score': 0.0871,\n",
    " 'model': 'sentence-transformers/all-roberta-large-v1',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    "\n",
    "{'max_pos_score': 0.36779,\n",
    " 'f2_score': 0.089,\n",
    " 'model': 'sentence-transformers/all-distilroberta-v1',\n",
    " 'top_k': 50} title + language_ + description for both, model.max_seq_length = 50\n",
    " \n",
    " {'max_pos_score': 0.34561,\n",
    " 'f2_score': 0.0817,\n",
    " 'model': 'sentence-transformers/stsb-roberta-base-v2',\n",
    " 'top_k': 50}\n",
    " \n",
    " {'max_pos_score': 0.75904,\n",
    " 'f2_score': 0.2119,\n",
    " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-10-seq-128-tuned/',\n",
    " 'top_k': 50}\n",
    " \n",
    " {'max_pos_score': 0.80749,\n",
    " 'f2_score': 0.2248,\n",
    " 'model': 'model/stage-1-all-mpnet-base-v2-epochs-20-seq-50-tuned/',\n",
    " 'top_k': 50}\n",
    " \n",
    " {'max_pos_score': 0.81499,\n",
    " 'f2_score': 0.2273,\n",
    " 'model': 'model/paraphrase-multilingual-mpnet-base-v2-epochs-30-tuned/', + 'model/stage-1-all-mpnet-base-v2-epochs-20-seq-50-tuned/'\n",
    " 'top_k': 50}\n",
    " \n",
    " {'max_pos_score': 0.71915,\n",
    " 'f2_score': 0.194,\n",
    " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-1-seq-64-tuned/',\n",
    " 'top_k': 50} fillna with text\n",
    " \n",
    " {'max_pos_score': 0.72691,\n",
    " 'f2_score': 0.1978,\n",
    " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-1-seq-50-tuned/',\n",
    " 'top_k': 50} fillna with text, kind, category for description,\n",
    " \n",
    " {'max_pos_score': 0.72892,\n",
    " 'f2_score': 0.1985,\n",
    " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-1-seq-50-tuned/',\n",
    " 'top_k': 50}\n",
    " \n",
    " {'max_pos_score': 0.84682,\n",
    " 'f2_score': 0.2343,\n",
    " 'model': 'model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-30-seq-50-tuned/',\n",
    " 'top_k': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying:model/stage-1-paraphrase-multilingual-mpnet-base-v2-epochs-30-seq-50-tuned/\n",
      " \n",
      "--------------------------------------------------\n",
      "topics.shape: (61517, 6)\n",
      "content.shape: (154047, 3)\n",
      "correlations.shape: (61517, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a652a75df343379b8a6a0f6c376add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/481 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484b2ac3a4364d478bdbcb03e39d11e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topics_embeds_all = []\n",
    "content_embeds_all = []\n",
    "for _idx, CFG in enumerate(CFG_list):\n",
    "    print(f'trying:{CFG.model}')\n",
    "    topics, content, correlations = read_data(CFG)\n",
    "    topics_embeds,content_embeds = get_neighbors(topics,content,CFG)\n",
    "    topics_embeds_all.append(topics_embeds)\n",
    "    content_embeds_all.append(content_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_embeds = np.concatenate(topics_embeds_all,axis=1)\n",
    "#content_embeds = np.concatenate(content_embeds_all,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61517, 768), (154047, 768))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_embeds.shape, content_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.rename(columns=lambda x: \"topic_\" + x, inplace=True)\n",
    "content.rename(columns=lambda x: \"content_\" + x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6675ca22cdc462e9c9d96d51659ad39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 29s, sys: 3.99 s, total: 14min 33s\n",
      "Wall time: 45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "model = AnnoyIndex(topics_embeds.shape[1], 'angular')\n",
    "\n",
    "for idx in tqdm(range(content_embeds.shape[0])):\n",
    "    model.add_item(idx, content_embeds[idx])\n",
    "    \n",
    "model.build(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c634a46270477ca01d0560ef609f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for topic_idx in tqdm(range(topics_embeds.shape[0])):\n",
    "    content_idx = model.get_nns_by_vector(topics_embeds[topic_idx],n=50)\n",
    "    df_temp = content[content.index.isin(content_idx)]\n",
    "    df_temp['topic_id'] = list(topics[topics.index.isin([topic_idx])].topic_id)[0]\n",
    "    df_temp['topic_title'] = list(topics[topics.index.isin([topic_idx])].topic_title)[0]\n",
    "    #df_temp['topic_language'] = list(topics[topics.index.isin([topic_idx])].topic_language)[0]\n",
    "    #df_temp['is_language'] = (df_temp['topic_language'] == df_temp['content_language'])\n",
    "    #df_temp = df_temp[(df_temp.is_language==True) | (df_temp.content_language=='en') | (df_temp.content_language=='es') | (df_temp.content_language=='fr') | (df_temp.content_language=='ar')]\n",
    "    if df_temp.shape[0] == 0:\n",
    "        break\n",
    "    #df_temp = df_temp.head(50)\n",
    "    #display(df_temp)\n",
    "    dfs.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = pd.concat(dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = candidates.groupby(['topic_id'])['content_id'].agg(list).reset_index()\n",
    "aa['predictions'] = aa.content_id.apply(lambda x: ' '.join(x))\n",
    "aa.drop('content_id',axis=1,inplace=True)\n",
    "topics_test = aa.merge(correlations, how = 'inner', left_on = ['topic_id'], right_on = ['topic_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our max positive score is 0.91713\n",
      "Our f2_score is 0.2592\n"
     ]
    }
   ],
   "source": [
    "pos_score = get_pos_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our max positive score is {pos_score}')\n",
    "\n",
    "f_score = f2_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our f2_score is {f_score}')\n",
    "\n",
    "#Validation\n",
    "#Our max positive score is 0.78403\n",
    "#Our f2_score is 0.2239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>predictions</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0feaaa5dc39d c_0262b16c8ecc c_82eaf550b23b c...</td>\n",
       "      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_14860bbee722 c_a72612bc23cb c_5b58b9ccaff5 c...</td>\n",
       "      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_55e9d6961b68 c_c33880dc08af c_2359fa003e04 c...</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_c9c743ee86c8 c_3850dfb9fe26 c_96f77eadfbb3 c...</td>\n",
       "      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0008768bdee6</td>\n",
       "      <td>c_7b1ff48ee7d2 c_a3c74443d8d3 c_6485703d86a9 c...</td>\n",
       "      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61512</th>\n",
       "      <td>t_fff830472691</td>\n",
       "      <td>c_28742eece061 c_d8e48c85f85a c_44c2ad81f467 c...</td>\n",
       "      <td>c_61fb63326e5d c_8f224e321c87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61513</th>\n",
       "      <td>t_fff9e5407d13</td>\n",
       "      <td>c_a86539ee631f c_18529667fd21 c_f27534a98779 c...</td>\n",
       "      <td>c_026db653a269 c_0fb048a6412c c_20de77522603 c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61514</th>\n",
       "      <td>t_fffbe1d5d43c</td>\n",
       "      <td>c_98b19801d2b8 c_2b3c03aeb915 c_92925992dce3 c...</td>\n",
       "      <td>c_46f852a49c08 c_6659207b25d5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61515</th>\n",
       "      <td>t_fffe14f1be1e</td>\n",
       "      <td>c_3f0bfa926d34 c_0744bf5a1016 c_ecbc9b167087 c...</td>\n",
       "      <td>c_cece166bad6a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61516</th>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>c_d8fa752a1df4 c_7aedbc7c1d0b c_735f01550bba c...</td>\n",
       "      <td>c_92b8fad372ee</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61517 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic_id                                        predictions  \\\n",
       "0      t_00004da3a1b2  c_0feaaa5dc39d c_0262b16c8ecc c_82eaf550b23b c...   \n",
       "1      t_00068291e9a4  c_14860bbee722 c_a72612bc23cb c_5b58b9ccaff5 c...   \n",
       "2      t_00069b63a70a  c_55e9d6961b68 c_c33880dc08af c_2359fa003e04 c...   \n",
       "3      t_0006d41a73a8  c_c9c743ee86c8 c_3850dfb9fe26 c_96f77eadfbb3 c...   \n",
       "4      t_0008768bdee6  c_7b1ff48ee7d2 c_a3c74443d8d3 c_6485703d86a9 c...   \n",
       "...               ...                                                ...   \n",
       "61512  t_fff830472691  c_28742eece061 c_d8e48c85f85a c_44c2ad81f467 c...   \n",
       "61513  t_fff9e5407d13  c_a86539ee631f c_18529667fd21 c_f27534a98779 c...   \n",
       "61514  t_fffbe1d5d43c  c_98b19801d2b8 c_2b3c03aeb915 c_92925992dce3 c...   \n",
       "61515  t_fffe14f1be1e  c_3f0bfa926d34 c_0744bf5a1016 c_ecbc9b167087 c...   \n",
       "61516  t_fffe811a6da9  c_d8fa752a1df4 c_7aedbc7c1d0b c_735f01550bba c...   \n",
       "\n",
       "                                             content_ids  fold  \n",
       "0      c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...     1  \n",
       "1      c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...     1  \n",
       "2                                         c_11a1dc0bfb99     4  \n",
       "3      c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...     2  \n",
       "4           c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4     0  \n",
       "...                                                  ...   ...  \n",
       "61512                      c_61fb63326e5d c_8f224e321c87     1  \n",
       "61513  c_026db653a269 c_0fb048a6412c c_20de77522603 c...     4  \n",
       "61514                      c_46f852a49c08 c_6659207b25d5     2  \n",
       "61515                                     c_cece166bad6a     2  \n",
       "61516                                     c_92b8fad372ee     3  \n",
       "\n",
       "[61517 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Train Data for Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_test['predictions'] = topics_test.predictions.apply(lambda x: x.split(' '))\n",
    "topics_test['content_ids'] = topics_test.content_ids.apply(lambda x: x.split(' '))\n",
    "gt = topics_test[['topic_id','content_ids','fold']].explode('content_ids')\n",
    "preds = topics_test[['topic_id','predictions','fold']].explode('predictions')\n",
    "candidates_df = preds.merge(gt[['topic_id','content_ids']],how='left',left_on=['topic_id','predictions'], right_on=['topic_id','content_ids'])\n",
    "candidates_df.loc[candidates_df.content_ids.isnull(),'target'] = 0\n",
    "candidates_df['target'] = candidates_df.target.fillna(1)\n",
    "candidates_df.drop('content_ids',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61517"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df.topic_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = candidates_df.rename(columns={'predictions':'content_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df = candidates_df.merge(topics[['topic_id','topic_title']],on='topic_id')\n",
    "candidates_df = candidates_df.merge(content[['content_id','content_title']],on='content_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3075850, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>content_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Откриването на резисторите. Language_bg. Descr...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_261fb7043ad1</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Електричен ток и електрично напрежение. Langua...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_3a1f5ae9f991</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Вериги с кондензатори. Language_bg. Descriptio...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3d7c26606337</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Електрична енергия. Language_bg. Description: ...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_3f678784db83</td>\n",
       "      <td>c_0feaaa5dc39d</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Проводници, полупроводници и изолатори. Langua...</td>\n",
       "      <td>Успоредно свързани резистори. Language_bg. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075845</th>\n",
       "      <td>t_fec51244ee9c</td>\n",
       "      <td>c_cbdb0582963f</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lineamientos Curriculares y Estándares. Langua...</td>\n",
       "      <td>Xeometría analítica do plano. Language_es. Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075846</th>\n",
       "      <td>t_ff6b5744fa8b</td>\n",
       "      <td>c_3be3ab256094</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Keyboard Usage [01-DL-03]. Language_en. Descri...</td>\n",
       "      <td>3.8: Binary Search. Language_en. Description: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075847</th>\n",
       "      <td>t_ff943400e210</td>\n",
       "      <td>c_74b9ad11c33f</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>折纸 ：简易. Language_zh. Description: source</td>\n",
       "      <td>折纸：简易信封. Language_zh. Description: \\n折纸：简易信封\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075848</th>\n",
       "      <td>t_ffa805102384</td>\n",
       "      <td>c_a9d88569a340</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>المِلْكيَّةُ الفِكْريَّةُ. Language_ar. Descri...</td>\n",
       "      <td>المِلْكيَّةُ الفِكْريَّةُ. Language_ar. Descri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075849</th>\n",
       "      <td>t_ffb0a70e5e48</td>\n",
       "      <td>c_8347e930f7ad</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Components of angles, naming an angle. Languag...</td>\n",
       "      <td>Level 2: Naming an Angle. Language_en. Descrip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3075850 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic_id      content_id  fold  target  \\\n",
       "0        t_00004da3a1b2  c_0feaaa5dc39d     1     0.0   \n",
       "1        t_261fb7043ad1  c_0feaaa5dc39d     3     0.0   \n",
       "2        t_3a1f5ae9f991  c_0feaaa5dc39d     0     0.0   \n",
       "3        t_3d7c26606337  c_0feaaa5dc39d     4     0.0   \n",
       "4        t_3f678784db83  c_0feaaa5dc39d     0     0.0   \n",
       "...                 ...             ...   ...     ...   \n",
       "3075845  t_fec51244ee9c  c_cbdb0582963f     3     0.0   \n",
       "3075846  t_ff6b5744fa8b  c_3be3ab256094     4     0.0   \n",
       "3075847  t_ff943400e210  c_74b9ad11c33f     3     1.0   \n",
       "3075848  t_ffa805102384  c_a9d88569a340     2     1.0   \n",
       "3075849  t_ffb0a70e5e48  c_8347e930f7ad     1     0.0   \n",
       "\n",
       "                                               topic_title  \\\n",
       "0        Откриването на резисторите. Language_bg. Descr...   \n",
       "1        Електричен ток и електрично напрежение. Langua...   \n",
       "2        Вериги с кондензатори. Language_bg. Descriptio...   \n",
       "3        Електрична енергия. Language_bg. Description: ...   \n",
       "4        Проводници, полупроводници и изолатори. Langua...   \n",
       "...                                                    ...   \n",
       "3075845  Lineamientos Curriculares y Estándares. Langua...   \n",
       "3075846  Keyboard Usage [01-DL-03]. Language_en. Descri...   \n",
       "3075847           折纸 ：简易. Language_zh. Description: source   \n",
       "3075848  المِلْكيَّةُ الفِكْريَّةُ. Language_ar. Descri...   \n",
       "3075849  Components of angles, naming an angle. Languag...   \n",
       "\n",
       "                                             content_title  \n",
       "0        Успоредно свързани резистори. Language_bg. Des...  \n",
       "1        Успоредно свързани резистори. Language_bg. Des...  \n",
       "2        Успоредно свързани резистори. Language_bg. Des...  \n",
       "3        Успоредно свързани резистори. Language_bg. Des...  \n",
       "4        Успоредно свързани резистори. Language_bg. Des...  \n",
       "...                                                    ...  \n",
       "3075845  Xeometría analítica do plano. Language_es. Des...  \n",
       "3075846  3.8: Binary Search. Language_en. Description: ...  \n",
       "3075847  折纸：简易信封. Language_zh. Description: \\n折纸：简易信封\\...  \n",
       "3075848  المِلْكيَّةُ الفِكْريَّةُ. Language_ar. Descri...  \n",
       "3075849  Level 2: Naming an Angle. Language_en. Descrip...  \n",
       "\n",
       "[3075850 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = pd.read_csv('data/train_top50_fold0_cv_with_groundtruth_final_72044.csv')#.fold.unique()#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df.columns = ['topics_ids','content_ids','fold','target','title1','title2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df[['topics_ids', 'content_ids', 'title1', 'title2', 'target', 'fold']].to_parquet('data/candidates_50_train_8468.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL DATA\n",
    "------------------------------------------------------------------\n",
    "#### NO TUNE\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sbert-models/paraphrase-multilingual-MiniLM-L12-v2\n",
    "Our max positive score is 0.41649\n",
    "Our f2_score is 0.1007\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sentence-embedding-models/paraphrase-MiniLM-L12-v2\n",
    "Our max positive score is 0.44421\n",
    "Our f2_score is 0.1099\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sentence-embedding-models/paraphrase-mpnet-base-v2\n",
    "Our max positive score is 0.45422\n",
    "Our f2_score is 0.1133\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2\n",
    "Our max positive score is 0.42578\n",
    "Our f2_score is 0.1033\n",
    "\n",
    "---------------\n",
    "TOP 50\n",
    "/kaggle/input/paraphrasemultilingualmpnetbasev2/all-MiniLM-L6-v2\n",
    "Our max positive score is 0.47988\n",
    "Our f2_score is 0.1216\n",
    "\n",
    "------------------------------------------------------------------\n",
    "#### TUNED\n",
    "----------------\n",
    "TOP 50\n",
    "'/kaggle/input/paraphrase-multilingual-mpnet-base-v2-tuned/paraphrase-multilingual-mpnet-base-v2-exp_fold0_epochs8'\n",
    "Our max positive score is 0.68706\n",
    "Our f2_score is 0.1902\n",
    "\n",
    "----------------\n",
    "TOP 50\n",
    "'/kaggle/input/stage-1-tuned/paraphrase-multilingual-mpnet-base-v2-tuned' ##15 epoch\n",
    "Our max positive score is 0.72044\n",
    "Our f2_score is 0.201\n",
    "\n",
    "---------------\n",
    "TOP 50\n",
    "'/kaggle/input/all-minilm-l6-v2-tuned/all-MiniLM-L6-v2_fold0_epochs20/all-MiniLM-L6-v2_fold0_epochs20'\n",
    "Our max positive score is 0.62932\n",
    "Our f2_score is 0.1713\n",
    "\n",
    "---------------\n",
    "TOP 50\n",
    "'/kaggle/input/all-minilm-l6-v2-tuned/all-MiniLM-L6-v2_fold0_epochs8/all-MiniLM-L6-v2_fold0_epochs8'\n",
    "Our max positive score is 0.59703\n",
    "Our f2_score is 0.1607"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T20:20:01.244452Z",
     "iopub.status.busy": "2023-02-18T20:20:01.244038Z",
     "iopub.status.idle": "2023-02-18T20:21:04.060718Z",
     "shell.execute_reply": "2023-02-18T20:21:04.059568Z",
     "shell.execute_reply.started": "2023-02-18T20:20:01.244415Z"
    }
   },
   "source": [
    "# Build training set\n",
    "full_correlations = pd.read_csv('/kaggle/input/all-minilm-l6-v2-tuned/kfold_correlations.csv')\n",
    "topics_full = topics.merge(full_correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "topics_full['predictions'] = topics_full.apply(lambda x: ' '.join(list(set(x.predictions.split(' ') + x.content_ids.split(' ')))) \\\n",
    "                                               if x.fold != 0 else x.predictions, axis = 1)\n",
    "train = build_training_set(topics_full, content, CFG)\n",
    "print(f'Our training set has {len(train)} rows')\n",
    "# Save train set to disk to train on another notebook\n",
    "train.to_csv(f'train_top{CFG.top_n}_fold0_cv_with_groundtruth_final_72044.csv', index = False)\n",
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

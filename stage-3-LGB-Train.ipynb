{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cf22a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 24 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import Levenshtein\n",
    "import difflib\n",
    "import gc\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True,nb_workers=24)\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "#import pylcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afda23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = pd.read_parquet('data/target.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe5d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'train'\n",
    "candidate_df = pd.read_csv('data/train_top50_fold0_cv_with_groundtruth_final_72044.csv')[['topics_ids','content_ids','target','fold']]\n",
    "if MODE == 'val':\n",
    "    candidate_df = candidate_df[candidate_df.fold == 0]\n",
    "    X_embeds = np.load(f'data/features_50_{MODE}.npy')\n",
    "if MODE != 'val':\n",
    "    candidate_df = candidate_df[candidate_df.fold != 0]\n",
    "    X_embeds = np.load(f'data/features_50_{MODE}.npy')\n",
    "candidate_df = candidate_df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "054fc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df.columns = ['topic_id','content_id','target','fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db93301f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_8a2c8da77d0c</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_3f51421a7c85</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_db7818729577</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_eb7d5e2e1744</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_60dd2fc8a271</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119822</th>\n",
       "      <td>t_70da08637930</td>\n",
       "      <td>c_70b185780f10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119823</th>\n",
       "      <td>t_70da08637930</td>\n",
       "      <td>c_40b1fea5ad01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119824</th>\n",
       "      <td>t_70da08637930</td>\n",
       "      <td>c_a73aa42d1be9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119825</th>\n",
       "      <td>t_70da08637930</td>\n",
       "      <td>c_dbce33468856</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119826</th>\n",
       "      <td>t_70da08637930</td>\n",
       "      <td>c_335661ac7b89</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504627 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic_id      content_id  target  fold\n",
       "0        t_3d9ad9931021  c_8a2c8da77d0c       1     3\n",
       "1        t_3d9ad9931021  c_3f51421a7c85       0     3\n",
       "2        t_3d9ad9931021  c_db7818729577       0     3\n",
       "3        t_3d9ad9931021  c_eb7d5e2e1744       0     3\n",
       "4        t_3d9ad9931021  c_60dd2fc8a271       0     3\n",
       "...                 ...             ...     ...   ...\n",
       "3119822  t_70da08637930  c_70b185780f10       0     2\n",
       "3119823  t_70da08637930  c_40b1fea5ad01       0     2\n",
       "3119824  t_70da08637930  c_a73aa42d1be9       0     2\n",
       "3119825  t_70da08637930  c_dbce33468856       0     2\n",
       "3119826  t_70da08637930  c_335661ac7b89       0     2\n",
       "\n",
       "[2504627 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fa75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv('data/topics.csv')\n",
    "content = pd.read_csv('data/content.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "#topics = topics[topics.id.isin(sample_submission.topic_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2327b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_columns = ['id','title','description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4af0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = content[used_columns].add_prefix('content_')\n",
    "topics = topics[used_columns].add_prefix('topic_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54536001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_df = candidate_df.merge(content,how='left',on=['content_id'])\n",
    "candidate_df = candidate_df.merge(topics,how='left',on=['topic_id'])\n",
    "del topics,content;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e03935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    return df\n",
    "\n",
    "def categorical_similarity(A, B):\n",
    "    if not A or not B:\n",
    "        return -1\n",
    "\n",
    "    A = set(str(A).split(\", \"))\n",
    "    B = set(str(B).split(\", \"))\n",
    "\n",
    "    # Find intersection of two sets\n",
    "    nominator = A.intersection(B)\n",
    "\n",
    "    similarity_1 = len(nominator) / len(A)\n",
    "    similarity_2 = len(nominator) / len(B)\n",
    "\n",
    "    return max(similarity_1, similarity_2)\n",
    "\n",
    "def string_operation(s1, s2, op=\"seq_matcher\"):\n",
    "    if s1 and s2:\n",
    "        if op == \"seq_matcher\":\n",
    "            return difflib.SequenceMatcher(None, s1, s2).ratio()\n",
    "        elif op == \"lev_distance\":\n",
    "            return Levenshtein.distance(s1, s2)\n",
    "        elif op == \"jaro_winkler\":\n",
    "            return Levenshtein.jaro_winkler(s1, s2)\n",
    "        elif op == \"lcs\":\n",
    "            return FastLCS(str(s1), str(s2))\n",
    "        elif op == \"wratio\":\n",
    "            return fuzz.WRatio(s1, s2)\n",
    "        elif op == \"partialratio\":\n",
    "            return fuzz.partial_ratio(s1, s2)\n",
    "        elif op == \"superfastlcs\":\n",
    "            return pylcs.lcs_sequence_length(s1, s2)\n",
    "            \n",
    "    else:\n",
    "        return -1\n",
    "def isna_features(df,columns):\n",
    "    for col in columns:\n",
    "        df[f'{col}_isna'] = df[col].isnull().astype(int)\n",
    "    df = reduce_memory(df)\n",
    "    return df\n",
    "\n",
    "def fillna_cols(df,columns):\n",
    "    df_copy = df.copy()\n",
    "    for col in columns:\n",
    "        if 'title' in col:\n",
    "            df_copy[col].fillna('no title',inplace=True)\n",
    "        if 'description' in col:\n",
    "            df_copy[col].fillna('no description',inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "def gc_clear():\n",
    "    for i in range(5):\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dad2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = isna_features(candidate_df,['content_title','content_description','topic_title','topic_description'])\n",
    "candidate_df = fillna_cols(candidate_df,['content_title','content_description','topic_title','topic_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4872221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea2d16e60f749ea814d014e2db2a16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0172c70d394b2fa6e67ad2660e9182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdd8ac834214a1ab944d61095271dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb3733209c4f068cbad8f203ede857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866ca4cf06a44ee3adbdb211d5b11d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d25aa21f18344a3bc65d5454d57b7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c983e8da11e4ad690c22f060c6e3b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d876e1f53e0940dfa97e6793aa771088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0745497df2445be8481257e80836c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d397dba78ef641ee908573ef3384e42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af83985f4360409c943038394def0b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b22009c6d894bbabbf498753511d2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9050d9cd4a4f868e4a1181fb08ba93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=104360), Label(value='0 / 104360')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_distance_features(df,similarity_cols):\n",
    "\n",
    "    #df[f\"categories_venn\"] = df[['categories' + \"_x\", 'categories' + \"_y\"]].apply(lambda x: categorical_similarity(x['categories' + \"_x\"], x['categories' + \"_y\"]),axis=1)\n",
    "    for c in tqdm(similarity_cols):\n",
    "        df['content_' + c] = df['content_' + c].astype(str)\n",
    "        df['topic_' + c] = df['topic_' + c].astype(str)\n",
    "        df[f\"{c}_partialratio\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: string_operation(x['topic_' + c], x['content_' + c],op=\"partialratio\"),axis=1)\n",
    "        #df[f\"{c}_lcs\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: string_operation(x['topic_' + c], x['content_' + c],op=\"lcs\"),axis=1)\n",
    "        df[f\"{c}_wratio\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: string_operation(x['topic_' + c], x['content_' + c],op=\"wratio\"),axis=1)\n",
    "        df[f\"{c}_seqm\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: string_operation(x['topic_' + c], x['content_' + c],op=\"seq_matcher\"),axis=1)\n",
    "        df[f\"{c}_leven\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: string_operation(x['topic_' + c], x['content_' + c],op=\"lev_distance\"),axis=1)           \n",
    "        df[f\"{c}_jaro\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: string_operation(x['topic_' + c], x['content_' + c],op=\"jaro_winkler\"),axis=1)\n",
    "        df[f\"{c}_venn\"] = df[['topic_' + c, 'content_' + c]].parallel_apply(lambda x: categorical_similarity(x['topic_' + c], x['content_' + c]),axis=1)\n",
    "        \n",
    "        df[f\"{c}_len\"] = df['content_' + c].astype(str).map(len)\n",
    "        df[f\"{c}_len2\"] = df['topic_' + c].astype(str).map(len)\n",
    "        df[f'{c}_len_diff'] = np.abs(df[f\"{c}_len\"] - df[f\"{c}_len2\"])\n",
    "        df[f\"{c}_nleven\"] = df[f'{c}_leven'] / \\\n",
    "                                df[[f'{c}_len', f'{c}_len2']].max(axis=1)\n",
    "\n",
    "        #df = df.drop(columns=f'{c}_len', axis=1)\n",
    "        #df = df.drop(columns=f'{c}_len2', axis=1)\n",
    "        df = reduce_memory(df)\n",
    "        #df.drop(columns=[c + \"_x\", c + \"_y\"], axis=1, inplace=True)\n",
    "        gc.collect()\n",
    "\n",
    "    return df\n",
    "similarity_cols = ['description','title']\n",
    "candidate_df = add_distance_features(candidate_df,similarity_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66255f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['content_title','content_description','topic_title','topic_description']\n",
    "candidate_df = candidate_df.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f1b08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = candidate_df['topic_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827fac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = candidate_df[['topic_id','content_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dfbf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = candidate_df.drop(['target','fold','topic_id','content_id'],axis=1)\n",
    "y = candidate_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "437bb5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2504627, 1536), (2504627, 24))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embeds.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b23f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0a8aca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "(2003716, 1536) (500911, 1536)\n",
      "training PCA..\n",
      "(2003716, 100) (500911, 100)\n",
      "Final Shape (2003716, 124) (500911, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.261300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.239639\tvalid_1's binary_logloss: 0.244676\n",
      "[200]\ttraining's binary_logloss: 0.225216\tvalid_1's binary_logloss: 0.233285\n",
      "[300]\ttraining's binary_logloss: 0.217194\tvalid_1's binary_logloss: 0.22817\n",
      "[400]\ttraining's binary_logloss: 0.210991\tvalid_1's binary_logloss: 0.22448\n",
      "[500]\ttraining's binary_logloss: 0.205656\tvalid_1's binary_logloss: 0.221443\n",
      "[600]\ttraining's binary_logloss: 0.200834\tvalid_1's binary_logloss: 0.218904\n",
      "[700]\ttraining's binary_logloss: 0.196641\tvalid_1's binary_logloss: 0.216792\n",
      "[800]\ttraining's binary_logloss: 0.19271\tvalid_1's binary_logloss: 0.214939\n",
      "[900]\ttraining's binary_logloss: 0.189064\tvalid_1's binary_logloss: 0.213264\n",
      "[1000]\ttraining's binary_logloss: 0.185754\tvalid_1's binary_logloss: 0.211791\n",
      "[1100]\ttraining's binary_logloss: 0.182453\tvalid_1's binary_logloss: 0.210342\n",
      "[1200]\ttraining's binary_logloss: 0.179194\tvalid_1's binary_logloss: 0.208774\n",
      "[1300]\ttraining's binary_logloss: 0.176192\tvalid_1's binary_logloss: 0.207486\n",
      "[1400]\ttraining's binary_logloss: 0.17341\tvalid_1's binary_logloss: 0.206301\n",
      "[1500]\ttraining's binary_logloss: 0.170833\tvalid_1's binary_logloss: 0.205327\n",
      "[1600]\ttraining's binary_logloss: 0.168249\tvalid_1's binary_logloss: 0.204233\n",
      "[1700]\ttraining's binary_logloss: 0.165743\tvalid_1's binary_logloss: 0.203169\n",
      "[1800]\ttraining's binary_logloss: 0.163366\tvalid_1's binary_logloss: 0.202213\n",
      "[1900]\ttraining's binary_logloss: 0.161202\tvalid_1's binary_logloss: 0.201453\n",
      "[2000]\ttraining's binary_logloss: 0.158895\tvalid_1's binary_logloss: 0.200548\n",
      "[2100]\ttraining's binary_logloss: 0.156732\tvalid_1's binary_logloss: 0.199752\n",
      "[2200]\ttraining's binary_logloss: 0.154587\tvalid_1's binary_logloss: 0.198946\n",
      "[2300]\ttraining's binary_logloss: 0.152508\tvalid_1's binary_logloss: 0.198152\n",
      "[2400]\ttraining's binary_logloss: 0.150493\tvalid_1's binary_logloss: 0.197407\n",
      "[2500]\ttraining's binary_logloss: 0.148546\tvalid_1's binary_logloss: 0.196668\n",
      "[2600]\ttraining's binary_logloss: 0.146624\tvalid_1's binary_logloss: 0.19604\n",
      "[2700]\ttraining's binary_logloss: 0.144789\tvalid_1's binary_logloss: 0.195442\n",
      "[2800]\ttraining's binary_logloss: 0.14298\tvalid_1's binary_logloss: 0.19484\n",
      "[2900]\ttraining's binary_logloss: 0.14129\tvalid_1's binary_logloss: 0.19433\n",
      "[3000]\ttraining's binary_logloss: 0.139549\tvalid_1's binary_logloss: 0.193678\n",
      "[3100]\ttraining's binary_logloss: 0.13791\tvalid_1's binary_logloss: 0.193118\n",
      "[3200]\ttraining's binary_logloss: 0.136233\tvalid_1's binary_logloss: 0.192658\n",
      "[3300]\ttraining's binary_logloss: 0.134658\tvalid_1's binary_logloss: 0.192154\n",
      "[3400]\ttraining's binary_logloss: 0.133071\tvalid_1's binary_logloss: 0.191622\n",
      "[3500]\ttraining's binary_logloss: 0.131556\tvalid_1's binary_logloss: 0.191166\n",
      "[3600]\ttraining's binary_logloss: 0.130059\tvalid_1's binary_logloss: 0.190673\n",
      "[3700]\ttraining's binary_logloss: 0.128595\tvalid_1's binary_logloss: 0.190294\n",
      "[3800]\ttraining's binary_logloss: 0.127236\tvalid_1's binary_logloss: 0.189906\n",
      "[3900]\ttraining's binary_logloss: 0.125855\tvalid_1's binary_logloss: 0.189491\n",
      "[4000]\ttraining's binary_logloss: 0.124517\tvalid_1's binary_logloss: 0.189099\n",
      "[4100]\ttraining's binary_logloss: 0.123235\tvalid_1's binary_logloss: 0.188768\n",
      "[4200]\ttraining's binary_logloss: 0.121979\tvalid_1's binary_logloss: 0.188438\n",
      "[4300]\ttraining's binary_logloss: 0.120739\tvalid_1's binary_logloss: 0.188176\n",
      "[4400]\ttraining's binary_logloss: 0.119463\tvalid_1's binary_logloss: 0.187827\n",
      "[4500]\ttraining's binary_logloss: 0.118238\tvalid_1's binary_logloss: 0.187615\n",
      "[4600]\ttraining's binary_logloss: 0.117028\tvalid_1's binary_logloss: 0.187291\n",
      "[4700]\ttraining's binary_logloss: 0.115841\tvalid_1's binary_logloss: 0.186988\n",
      "[4800]\ttraining's binary_logloss: 0.114684\tvalid_1's binary_logloss: 0.186685\n",
      "[4900]\ttraining's binary_logloss: 0.113564\tvalid_1's binary_logloss: 0.186406\n",
      "[5000]\ttraining's binary_logloss: 0.112446\tvalid_1's binary_logloss: 0.186109\n",
      "[5100]\ttraining's binary_logloss: 0.111365\tvalid_1's binary_logloss: 0.185839\n",
      "[5200]\ttraining's binary_logloss: 0.110286\tvalid_1's binary_logloss: 0.185625\n",
      "[5300]\ttraining's binary_logloss: 0.109233\tvalid_1's binary_logloss: 0.185418\n",
      "[5400]\ttraining's binary_logloss: 0.108214\tvalid_1's binary_logloss: 0.185197\n",
      "[5500]\ttraining's binary_logloss: 0.107179\tvalid_1's binary_logloss: 0.184929\n",
      "[5600]\ttraining's binary_logloss: 0.106174\tvalid_1's binary_logloss: 0.184715\n",
      "[5700]\ttraining's binary_logloss: 0.10519\tvalid_1's binary_logloss: 0.184525\n",
      "[5800]\ttraining's binary_logloss: 0.104245\tvalid_1's binary_logloss: 0.184321\n",
      "[5900]\ttraining's binary_logloss: 0.103336\tvalid_1's binary_logloss: 0.18416\n",
      "[6000]\ttraining's binary_logloss: 0.102388\tvalid_1's binary_logloss: 0.183976\n",
      "[6100]\ttraining's binary_logloss: 0.101478\tvalid_1's binary_logloss: 0.183795\n",
      "[6200]\ttraining's binary_logloss: 0.100585\tvalid_1's binary_logloss: 0.183696\n",
      "[6300]\ttraining's binary_logloss: 0.0996783\tvalid_1's binary_logloss: 0.183547\n",
      "[6400]\ttraining's binary_logloss: 0.0988129\tvalid_1's binary_logloss: 0.183417\n",
      "[6500]\ttraining's binary_logloss: 0.0979555\tvalid_1's binary_logloss: 0.183244\n",
      "[6600]\ttraining's binary_logloss: 0.0971079\tvalid_1's binary_logloss: 0.183107\n",
      "[6700]\ttraining's binary_logloss: 0.0962469\tvalid_1's binary_logloss: 0.183007\n",
      "[6800]\ttraining's binary_logloss: 0.0954087\tvalid_1's binary_logloss: 0.182912\n",
      "[6900]\ttraining's binary_logloss: 0.0945797\tvalid_1's binary_logloss: 0.182752\n",
      "[7000]\ttraining's binary_logloss: 0.0937862\tvalid_1's binary_logloss: 0.182659\n",
      "[7100]\ttraining's binary_logloss: 0.0929827\tvalid_1's binary_logloss: 0.182554\n",
      "[7200]\ttraining's binary_logloss: 0.0922109\tvalid_1's binary_logloss: 0.182433\n",
      "[7300]\ttraining's binary_logloss: 0.0914352\tvalid_1's binary_logloss: 0.182345\n",
      "[7400]\ttraining's binary_logloss: 0.0906983\tvalid_1's binary_logloss: 0.182284\n",
      "[7500]\ttraining's binary_logloss: 0.0899476\tvalid_1's binary_logloss: 0.182163\n",
      "[7600]\ttraining's binary_logloss: 0.0891969\tvalid_1's binary_logloss: 0.182101\n",
      "[7700]\ttraining's binary_logloss: 0.0884561\tvalid_1's binary_logloss: 0.182041\n",
      "[7800]\ttraining's binary_logloss: 0.087754\tvalid_1's binary_logloss: 0.182018\n",
      "[7900]\ttraining's binary_logloss: 0.0870657\tvalid_1's binary_logloss: 0.181963\n",
      "[8000]\ttraining's binary_logloss: 0.0863862\tvalid_1's binary_logloss: 0.182001\n",
      "[8100]\ttraining's binary_logloss: 0.0857307\tvalid_1's binary_logloss: 0.18193\n",
      "[8200]\ttraining's binary_logloss: 0.0850643\tvalid_1's binary_logloss: 0.181862\n",
      "[8300]\ttraining's binary_logloss: 0.0843909\tvalid_1's binary_logloss: 0.181763\n",
      "[8400]\ttraining's binary_logloss: 0.0837354\tvalid_1's binary_logloss: 0.181715\n",
      "Early stopping, best iteration is:\n",
      "[8358]\ttraining's binary_logloss: 0.0840093\tvalid_1's binary_logloss: 0.181713\n",
      "Train F1:  0.7009087536724082\n",
      "Val F1 0.507233418162643\n",
      "Fold 1\n",
      "(2003722, 1536) (500905, 1536)\n",
      "training PCA..\n",
      "(2003722, 100) (500905, 100)\n",
      "Final Shape (2003722, 124) (500905, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.250576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.240161\tvalid_1's binary_logloss: 0.241972\n",
      "[200]\ttraining's binary_logloss: 0.226028\tvalid_1's binary_logloss: 0.231322\n",
      "[300]\ttraining's binary_logloss: 0.217784\tvalid_1's binary_logloss: 0.225845\n",
      "[400]\ttraining's binary_logloss: 0.211358\tvalid_1's binary_logloss: 0.221946\n",
      "[500]\ttraining's binary_logloss: 0.206161\tvalid_1's binary_logloss: 0.219081\n",
      "[600]\ttraining's binary_logloss: 0.201349\tvalid_1's binary_logloss: 0.216651\n",
      "[700]\ttraining's binary_logloss: 0.197163\tvalid_1's binary_logloss: 0.21467\n",
      "[800]\ttraining's binary_logloss: 0.193245\tvalid_1's binary_logloss: 0.212794\n",
      "[900]\ttraining's binary_logloss: 0.189487\tvalid_1's binary_logloss: 0.210873\n",
      "[1000]\ttraining's binary_logloss: 0.186116\tvalid_1's binary_logloss: 0.209166\n",
      "[1100]\ttraining's binary_logloss: 0.182879\tvalid_1's binary_logloss: 0.207593\n",
      "[1200]\ttraining's binary_logloss: 0.179925\tvalid_1's binary_logloss: 0.206195\n",
      "[1300]\ttraining's binary_logloss: 0.176889\tvalid_1's binary_logloss: 0.204778\n",
      "[1400]\ttraining's binary_logloss: 0.173874\tvalid_1's binary_logloss: 0.203383\n",
      "[1500]\ttraining's binary_logloss: 0.171112\tvalid_1's binary_logloss: 0.202155\n",
      "[1600]\ttraining's binary_logloss: 0.168469\tvalid_1's binary_logloss: 0.20096\n",
      "[1700]\ttraining's binary_logloss: 0.165937\tvalid_1's binary_logloss: 0.199903\n",
      "[1800]\ttraining's binary_logloss: 0.163479\tvalid_1's binary_logloss: 0.198889\n",
      "[1900]\ttraining's binary_logloss: 0.16116\tvalid_1's binary_logloss: 0.197837\n",
      "[2000]\ttraining's binary_logloss: 0.158981\tvalid_1's binary_logloss: 0.196984\n",
      "[2100]\ttraining's binary_logloss: 0.156857\tvalid_1's binary_logloss: 0.196095\n",
      "[2200]\ttraining's binary_logloss: 0.154788\tvalid_1's binary_logloss: 0.195331\n",
      "[2300]\ttraining's binary_logloss: 0.152767\tvalid_1's binary_logloss: 0.194529\n",
      "[2400]\ttraining's binary_logloss: 0.150654\tvalid_1's binary_logloss: 0.193721\n",
      "[2500]\ttraining's binary_logloss: 0.148766\tvalid_1's binary_logloss: 0.192969\n",
      "[2600]\ttraining's binary_logloss: 0.146862\tvalid_1's binary_logloss: 0.192268\n",
      "[2700]\ttraining's binary_logloss: 0.145012\tvalid_1's binary_logloss: 0.191547\n",
      "[2800]\ttraining's binary_logloss: 0.143314\tvalid_1's binary_logloss: 0.191004\n",
      "[2900]\ttraining's binary_logloss: 0.141607\tvalid_1's binary_logloss: 0.190437\n",
      "[3000]\ttraining's binary_logloss: 0.139852\tvalid_1's binary_logloss: 0.189841\n",
      "[3100]\ttraining's binary_logloss: 0.138141\tvalid_1's binary_logloss: 0.189228\n",
      "[3200]\ttraining's binary_logloss: 0.136547\tvalid_1's binary_logloss: 0.188687\n",
      "[3300]\ttraining's binary_logloss: 0.134951\tvalid_1's binary_logloss: 0.188157\n",
      "[3400]\ttraining's binary_logloss: 0.133431\tvalid_1's binary_logloss: 0.187675\n",
      "[3500]\ttraining's binary_logloss: 0.131934\tvalid_1's binary_logloss: 0.187175\n",
      "[3600]\ttraining's binary_logloss: 0.130504\tvalid_1's binary_logloss: 0.1868\n",
      "[3700]\ttraining's binary_logloss: 0.1291\tvalid_1's binary_logloss: 0.186359\n",
      "[3800]\ttraining's binary_logloss: 0.127706\tvalid_1's binary_logloss: 0.185984\n",
      "[3900]\ttraining's binary_logloss: 0.126357\tvalid_1's binary_logloss: 0.185595\n",
      "[4000]\ttraining's binary_logloss: 0.125022\tvalid_1's binary_logloss: 0.185265\n",
      "[4100]\ttraining's binary_logloss: 0.123688\tvalid_1's binary_logloss: 0.18487\n",
      "[4200]\ttraining's binary_logloss: 0.122382\tvalid_1's binary_logloss: 0.184515\n",
      "[4300]\ttraining's binary_logloss: 0.121135\tvalid_1's binary_logloss: 0.184153\n",
      "[4400]\ttraining's binary_logloss: 0.119871\tvalid_1's binary_logloss: 0.183819\n",
      "[4500]\ttraining's binary_logloss: 0.11864\tvalid_1's binary_logloss: 0.183469\n",
      "[4600]\ttraining's binary_logloss: 0.117406\tvalid_1's binary_logloss: 0.183095\n",
      "[4700]\ttraining's binary_logloss: 0.116253\tvalid_1's binary_logloss: 0.182773\n",
      "[4800]\ttraining's binary_logloss: 0.115086\tvalid_1's binary_logloss: 0.182449\n",
      "[4900]\ttraining's binary_logloss: 0.113906\tvalid_1's binary_logloss: 0.182132\n",
      "[5000]\ttraining's binary_logloss: 0.112801\tvalid_1's binary_logloss: 0.181894\n",
      "[5100]\ttraining's binary_logloss: 0.111688\tvalid_1's binary_logloss: 0.181619\n",
      "[5200]\ttraining's binary_logloss: 0.110607\tvalid_1's binary_logloss: 0.181329\n",
      "[5300]\ttraining's binary_logloss: 0.109559\tvalid_1's binary_logloss: 0.181087\n",
      "[5400]\ttraining's binary_logloss: 0.108538\tvalid_1's binary_logloss: 0.180837\n",
      "[5500]\ttraining's binary_logloss: 0.107507\tvalid_1's binary_logloss: 0.180603\n",
      "[5600]\ttraining's binary_logloss: 0.106508\tvalid_1's binary_logloss: 0.180359\n",
      "[5700]\ttraining's binary_logloss: 0.105528\tvalid_1's binary_logloss: 0.180175\n",
      "[5800]\ttraining's binary_logloss: 0.104567\tvalid_1's binary_logloss: 0.179947\n",
      "[5900]\ttraining's binary_logloss: 0.1036\tvalid_1's binary_logloss: 0.179747\n",
      "[6000]\ttraining's binary_logloss: 0.102677\tvalid_1's binary_logloss: 0.179524\n",
      "[6100]\ttraining's binary_logloss: 0.10174\tvalid_1's binary_logloss: 0.17937\n",
      "[6200]\ttraining's binary_logloss: 0.10082\tvalid_1's binary_logloss: 0.179216\n",
      "[6300]\ttraining's binary_logloss: 0.0999705\tvalid_1's binary_logloss: 0.179055\n",
      "[6400]\ttraining's binary_logloss: 0.099102\tvalid_1's binary_logloss: 0.178892\n",
      "[6500]\ttraining's binary_logloss: 0.0982387\tvalid_1's binary_logloss: 0.178705\n",
      "[6600]\ttraining's binary_logloss: 0.0973865\tvalid_1's binary_logloss: 0.17853\n",
      "[6700]\ttraining's binary_logloss: 0.0965603\tvalid_1's binary_logloss: 0.17842\n",
      "[6800]\ttraining's binary_logloss: 0.0957258\tvalid_1's binary_logloss: 0.178237\n",
      "[6900]\ttraining's binary_logloss: 0.0949177\tvalid_1's binary_logloss: 0.17806\n",
      "[7000]\ttraining's binary_logloss: 0.0941304\tvalid_1's binary_logloss: 0.177907\n",
      "[7100]\ttraining's binary_logloss: 0.0933485\tvalid_1's binary_logloss: 0.17776\n",
      "[7200]\ttraining's binary_logloss: 0.0925888\tvalid_1's binary_logloss: 0.177634\n",
      "[7300]\ttraining's binary_logloss: 0.0918342\tvalid_1's binary_logloss: 0.177542\n",
      "[7400]\ttraining's binary_logloss: 0.0910477\tvalid_1's binary_logloss: 0.177363\n",
      "[7500]\ttraining's binary_logloss: 0.0903263\tvalid_1's binary_logloss: 0.177284\n",
      "[7600]\ttraining's binary_logloss: 0.0895913\tvalid_1's binary_logloss: 0.177191\n",
      "[7700]\ttraining's binary_logloss: 0.0888511\tvalid_1's binary_logloss: 0.177081\n",
      "[7800]\ttraining's binary_logloss: 0.0881284\tvalid_1's binary_logloss: 0.176942\n",
      "[7900]\ttraining's binary_logloss: 0.0874419\tvalid_1's binary_logloss: 0.176865\n",
      "[8000]\ttraining's binary_logloss: 0.0867609\tvalid_1's binary_logloss: 0.176815\n",
      "[8100]\ttraining's binary_logloss: 0.0860732\tvalid_1's binary_logloss: 0.176715\n",
      "[8200]\ttraining's binary_logloss: 0.0854104\tvalid_1's binary_logloss: 0.176627\n",
      "[8300]\ttraining's binary_logloss: 0.0847691\tvalid_1's binary_logloss: 0.176571\n",
      "[8400]\ttraining's binary_logloss: 0.0841168\tvalid_1's binary_logloss: 0.176533\n",
      "[8500]\ttraining's binary_logloss: 0.0834564\tvalid_1's binary_logloss: 0.176463\n",
      "[8600]\ttraining's binary_logloss: 0.0828178\tvalid_1's binary_logloss: 0.176404\n",
      "[8700]\ttraining's binary_logloss: 0.0821938\tvalid_1's binary_logloss: 0.176355\n",
      "[8800]\ttraining's binary_logloss: 0.0815656\tvalid_1's binary_logloss: 0.176266\n",
      "[8900]\ttraining's binary_logloss: 0.0809574\tvalid_1's binary_logloss: 0.176163\n",
      "[9000]\ttraining's binary_logloss: 0.0803404\tvalid_1's binary_logloss: 0.176106\n",
      "[9100]\ttraining's binary_logloss: 0.079748\tvalid_1's binary_logloss: 0.176042\n",
      "[9200]\ttraining's binary_logloss: 0.0791591\tvalid_1's binary_logloss: 0.176017\n",
      "[9300]\ttraining's binary_logloss: 0.0785708\tvalid_1's binary_logloss: 0.175978\n",
      "[9400]\ttraining's binary_logloss: 0.0780135\tvalid_1's binary_logloss: 0.175905\n",
      "[9500]\ttraining's binary_logloss: 0.0774605\tvalid_1's binary_logloss: 0.175883\n",
      "[9600]\ttraining's binary_logloss: 0.0768958\tvalid_1's binary_logloss: 0.175878\n",
      "[9700]\ttraining's binary_logloss: 0.0763384\tvalid_1's binary_logloss: 0.175803\n",
      "[9800]\ttraining's binary_logloss: 0.0758063\tvalid_1's binary_logloss: 0.175817\n",
      "Early stopping, best iteration is:\n",
      "[9763]\ttraining's binary_logloss: 0.0760034\tvalid_1's binary_logloss: 0.175785\n",
      "Train F1:  0.7290234120873238\n",
      "Val F1 0.5221682643794147\n",
      "Fold 2\n",
      "(2003690, 1536) (500937, 1536)\n",
      "training PCA..\n",
      "(2003690, 100) (500937, 100)\n",
      "Final Shape (2003690, 124) (500937, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.252724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.239429\tvalid_1's binary_logloss: 0.245854\n",
      "[200]\ttraining's binary_logloss: 0.225044\tvalid_1's binary_logloss: 0.234603\n",
      "[300]\ttraining's binary_logloss: 0.217169\tvalid_1's binary_logloss: 0.229304\n",
      "[400]\ttraining's binary_logloss: 0.210823\tvalid_1's binary_logloss: 0.22546\n",
      "[500]\ttraining's binary_logloss: 0.205479\tvalid_1's binary_logloss: 0.222444\n",
      "[600]\ttraining's binary_logloss: 0.20079\tvalid_1's binary_logloss: 0.220022\n",
      "[700]\ttraining's binary_logloss: 0.196412\tvalid_1's binary_logloss: 0.217817\n",
      "[800]\ttraining's binary_logloss: 0.192534\tvalid_1's binary_logloss: 0.215913\n",
      "[900]\ttraining's binary_logloss: 0.188833\tvalid_1's binary_logloss: 0.214079\n",
      "[1000]\ttraining's binary_logloss: 0.18551\tvalid_1's binary_logloss: 0.212497\n",
      "[1100]\ttraining's binary_logloss: 0.182359\tvalid_1's binary_logloss: 0.211103\n",
      "[1200]\ttraining's binary_logloss: 0.179236\tvalid_1's binary_logloss: 0.20973\n",
      "[1300]\ttraining's binary_logloss: 0.176272\tvalid_1's binary_logloss: 0.208293\n",
      "[1400]\ttraining's binary_logloss: 0.173407\tvalid_1's binary_logloss: 0.206958\n",
      "[1500]\ttraining's binary_logloss: 0.170786\tvalid_1's binary_logloss: 0.205827\n",
      "[1600]\ttraining's binary_logloss: 0.168111\tvalid_1's binary_logloss: 0.204667\n",
      "[1700]\ttraining's binary_logloss: 0.165572\tvalid_1's binary_logloss: 0.203677\n",
      "[1800]\ttraining's binary_logloss: 0.163233\tvalid_1's binary_logloss: 0.202716\n",
      "[1900]\ttraining's binary_logloss: 0.160921\tvalid_1's binary_logloss: 0.201784\n",
      "[2000]\ttraining's binary_logloss: 0.158601\tvalid_1's binary_logloss: 0.20091\n",
      "[2100]\ttraining's binary_logloss: 0.156327\tvalid_1's binary_logloss: 0.200003\n",
      "[2200]\ttraining's binary_logloss: 0.154108\tvalid_1's binary_logloss: 0.199151\n",
      "[2300]\ttraining's binary_logloss: 0.152144\tvalid_1's binary_logloss: 0.198451\n",
      "[2400]\ttraining's binary_logloss: 0.150089\tvalid_1's binary_logloss: 0.197708\n",
      "[2500]\ttraining's binary_logloss: 0.148211\tvalid_1's binary_logloss: 0.197021\n",
      "[2600]\ttraining's binary_logloss: 0.146353\tvalid_1's binary_logloss: 0.196403\n",
      "[2700]\ttraining's binary_logloss: 0.144594\tvalid_1's binary_logloss: 0.195786\n",
      "[2800]\ttraining's binary_logloss: 0.142835\tvalid_1's binary_logloss: 0.1952\n",
      "[2900]\ttraining's binary_logloss: 0.141146\tvalid_1's binary_logloss: 0.194638\n",
      "[3000]\ttraining's binary_logloss: 0.139409\tvalid_1's binary_logloss: 0.194079\n",
      "[3100]\ttraining's binary_logloss: 0.137725\tvalid_1's binary_logloss: 0.193484\n",
      "[3200]\ttraining's binary_logloss: 0.136105\tvalid_1's binary_logloss: 0.192949\n",
      "[3300]\ttraining's binary_logloss: 0.134587\tvalid_1's binary_logloss: 0.192453\n",
      "[3400]\ttraining's binary_logloss: 0.13308\tvalid_1's binary_logloss: 0.191939\n",
      "[3500]\ttraining's binary_logloss: 0.131601\tvalid_1's binary_logloss: 0.191434\n",
      "[3600]\ttraining's binary_logloss: 0.130156\tvalid_1's binary_logloss: 0.191061\n",
      "[3700]\ttraining's binary_logloss: 0.128701\tvalid_1's binary_logloss: 0.190593\n",
      "[3800]\ttraining's binary_logloss: 0.127311\tvalid_1's binary_logloss: 0.190199\n",
      "[3900]\ttraining's binary_logloss: 0.125965\tvalid_1's binary_logloss: 0.18977\n",
      "[4000]\ttraining's binary_logloss: 0.12464\tvalid_1's binary_logloss: 0.189383\n",
      "[4100]\ttraining's binary_logloss: 0.123315\tvalid_1's binary_logloss: 0.189021\n",
      "[4200]\ttraining's binary_logloss: 0.122011\tvalid_1's binary_logloss: 0.188715\n",
      "[4300]\ttraining's binary_logloss: 0.120759\tvalid_1's binary_logloss: 0.18838\n",
      "[4400]\ttraining's binary_logloss: 0.119514\tvalid_1's binary_logloss: 0.188095\n",
      "[4500]\ttraining's binary_logloss: 0.118316\tvalid_1's binary_logloss: 0.18779\n",
      "[4600]\ttraining's binary_logloss: 0.117086\tvalid_1's binary_logloss: 0.187458\n",
      "[4700]\ttraining's binary_logloss: 0.115944\tvalid_1's binary_logloss: 0.187112\n",
      "[4800]\ttraining's binary_logloss: 0.114797\tvalid_1's binary_logloss: 0.186831\n",
      "[4900]\ttraining's binary_logloss: 0.113704\tvalid_1's binary_logloss: 0.186681\n",
      "[5000]\ttraining's binary_logloss: 0.112616\tvalid_1's binary_logloss: 0.186351\n",
      "[5100]\ttraining's binary_logloss: 0.111537\tvalid_1's binary_logloss: 0.186134\n",
      "[5200]\ttraining's binary_logloss: 0.110468\tvalid_1's binary_logloss: 0.185858\n",
      "[5300]\ttraining's binary_logloss: 0.109398\tvalid_1's binary_logloss: 0.185566\n",
      "[5400]\ttraining's binary_logloss: 0.10838\tvalid_1's binary_logloss: 0.185362\n",
      "[5500]\ttraining's binary_logloss: 0.107389\tvalid_1's binary_logloss: 0.185118\n",
      "[5600]\ttraining's binary_logloss: 0.106414\tvalid_1's binary_logloss: 0.184915\n",
      "[5700]\ttraining's binary_logloss: 0.105434\tvalid_1's binary_logloss: 0.184728\n",
      "[5800]\ttraining's binary_logloss: 0.104462\tvalid_1's binary_logloss: 0.184494\n",
      "[5900]\ttraining's binary_logloss: 0.103519\tvalid_1's binary_logloss: 0.184271\n",
      "[6000]\ttraining's binary_logloss: 0.10261\tvalid_1's binary_logloss: 0.184039\n",
      "[6100]\ttraining's binary_logloss: 0.101697\tvalid_1's binary_logloss: 0.18385\n",
      "[6200]\ttraining's binary_logloss: 0.10078\tvalid_1's binary_logloss: 0.183639\n",
      "[6300]\ttraining's binary_logloss: 0.0999206\tvalid_1's binary_logloss: 0.183453\n",
      "[6400]\ttraining's binary_logloss: 0.09903\tvalid_1's binary_logloss: 0.183281\n",
      "[6500]\ttraining's binary_logloss: 0.0981664\tvalid_1's binary_logloss: 0.183143\n",
      "[6600]\ttraining's binary_logloss: 0.0973191\tvalid_1's binary_logloss: 0.183074\n",
      "[6700]\ttraining's binary_logloss: 0.0964748\tvalid_1's binary_logloss: 0.182909\n",
      "[6800]\ttraining's binary_logloss: 0.095651\tvalid_1's binary_logloss: 0.182755\n",
      "[6900]\ttraining's binary_logloss: 0.0948409\tvalid_1's binary_logloss: 0.182673\n",
      "[7000]\ttraining's binary_logloss: 0.0940282\tvalid_1's binary_logloss: 0.182562\n",
      "[7100]\ttraining's binary_logloss: 0.0932647\tvalid_1's binary_logloss: 0.182444\n",
      "[7200]\ttraining's binary_logloss: 0.0925123\tvalid_1's binary_logloss: 0.182295\n",
      "[7300]\ttraining's binary_logloss: 0.0917188\tvalid_1's binary_logloss: 0.182172\n",
      "[7400]\ttraining's binary_logloss: 0.0909571\tvalid_1's binary_logloss: 0.182048\n",
      "[7500]\ttraining's binary_logloss: 0.0902168\tvalid_1's binary_logloss: 0.181984\n",
      "[7600]\ttraining's binary_logloss: 0.0894887\tvalid_1's binary_logloss: 0.181962\n",
      "[7700]\ttraining's binary_logloss: 0.0887561\tvalid_1's binary_logloss: 0.181819\n",
      "[7800]\ttraining's binary_logloss: 0.0880597\tvalid_1's binary_logloss: 0.181736\n",
      "[7900]\ttraining's binary_logloss: 0.0873589\tvalid_1's binary_logloss: 0.181659\n",
      "[8000]\ttraining's binary_logloss: 0.086661\tvalid_1's binary_logloss: 0.181569\n",
      "[8100]\ttraining's binary_logloss: 0.085979\tvalid_1's binary_logloss: 0.181524\n",
      "[8200]\ttraining's binary_logloss: 0.0853115\tvalid_1's binary_logloss: 0.181479\n",
      "[8300]\ttraining's binary_logloss: 0.0846469\tvalid_1's binary_logloss: 0.181462\n",
      "[8400]\ttraining's binary_logloss: 0.0839989\tvalid_1's binary_logloss: 0.18139\n",
      "Early stopping, best iteration is:\n",
      "[8399]\ttraining's binary_logloss: 0.0840054\tvalid_1's binary_logloss: 0.181386\n",
      "Train F1:  0.7001140296080357\n",
      "Val F1 0.5101709077098368\n",
      "Fold 3\n",
      "(2003690, 1536) (500937, 1536)\n",
      "training PCA..\n",
      "(2003690, 100) (500937, 100)\n",
      "Final Shape (2003690, 124) (500937, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.239954\tvalid_1's binary_logloss: 0.243698\n",
      "[200]\ttraining's binary_logloss: 0.225715\tvalid_1's binary_logloss: 0.232227\n",
      "[300]\ttraining's binary_logloss: 0.217525\tvalid_1's binary_logloss: 0.226689\n",
      "[400]\ttraining's binary_logloss: 0.211404\tvalid_1's binary_logloss: 0.222988\n",
      "[500]\ttraining's binary_logloss: 0.206022\tvalid_1's binary_logloss: 0.219891\n",
      "[600]\ttraining's binary_logloss: 0.201399\tvalid_1's binary_logloss: 0.217355\n",
      "[700]\ttraining's binary_logloss: 0.197024\tvalid_1's binary_logloss: 0.214891\n",
      "[800]\ttraining's binary_logloss: 0.193309\tvalid_1's binary_logloss: 0.213066\n",
      "[900]\ttraining's binary_logloss: 0.189805\tvalid_1's binary_logloss: 0.211392\n",
      "[1000]\ttraining's binary_logloss: 0.186197\tvalid_1's binary_logloss: 0.209632\n",
      "[1100]\ttraining's binary_logloss: 0.182835\tvalid_1's binary_logloss: 0.208011\n",
      "[1200]\ttraining's binary_logloss: 0.179679\tvalid_1's binary_logloss: 0.206533\n",
      "[1300]\ttraining's binary_logloss: 0.176944\tvalid_1's binary_logloss: 0.205379\n",
      "[1400]\ttraining's binary_logloss: 0.174151\tvalid_1's binary_logloss: 0.204216\n",
      "[1500]\ttraining's binary_logloss: 0.171354\tvalid_1's binary_logloss: 0.202986\n",
      "[1600]\ttraining's binary_logloss: 0.168672\tvalid_1's binary_logloss: 0.201818\n",
      "[1700]\ttraining's binary_logloss: 0.166209\tvalid_1's binary_logloss: 0.200772\n",
      "[1800]\ttraining's binary_logloss: 0.163824\tvalid_1's binary_logloss: 0.199808\n",
      "[1900]\ttraining's binary_logloss: 0.161558\tvalid_1's binary_logloss: 0.198944\n",
      "[2000]\ttraining's binary_logloss: 0.159223\tvalid_1's binary_logloss: 0.198086\n",
      "[2100]\ttraining's binary_logloss: 0.157005\tvalid_1's binary_logloss: 0.197167\n",
      "[2200]\ttraining's binary_logloss: 0.154782\tvalid_1's binary_logloss: 0.196282\n",
      "[2300]\ttraining's binary_logloss: 0.152773\tvalid_1's binary_logloss: 0.195513\n",
      "[2400]\ttraining's binary_logloss: 0.150799\tvalid_1's binary_logloss: 0.19476\n",
      "[2500]\ttraining's binary_logloss: 0.148896\tvalid_1's binary_logloss: 0.194114\n",
      "[2600]\ttraining's binary_logloss: 0.147091\tvalid_1's binary_logloss: 0.193531\n",
      "[2700]\ttraining's binary_logloss: 0.145392\tvalid_1's binary_logloss: 0.192929\n",
      "[2800]\ttraining's binary_logloss: 0.143546\tvalid_1's binary_logloss: 0.192283\n",
      "[2900]\ttraining's binary_logloss: 0.141916\tvalid_1's binary_logloss: 0.191724\n",
      "[3000]\ttraining's binary_logloss: 0.14016\tvalid_1's binary_logloss: 0.191121\n",
      "[3100]\ttraining's binary_logloss: 0.138492\tvalid_1's binary_logloss: 0.190562\n",
      "[3200]\ttraining's binary_logloss: 0.136869\tvalid_1's binary_logloss: 0.190096\n",
      "[3300]\ttraining's binary_logloss: 0.135318\tvalid_1's binary_logloss: 0.189567\n",
      "[3400]\ttraining's binary_logloss: 0.133757\tvalid_1's binary_logloss: 0.189093\n",
      "[3500]\ttraining's binary_logloss: 0.132211\tvalid_1's binary_logloss: 0.188595\n",
      "[3600]\ttraining's binary_logloss: 0.130716\tvalid_1's binary_logloss: 0.188155\n",
      "[3700]\ttraining's binary_logloss: 0.129316\tvalid_1's binary_logloss: 0.187727\n",
      "[3800]\ttraining's binary_logloss: 0.12791\tvalid_1's binary_logloss: 0.187241\n",
      "[3900]\ttraining's binary_logloss: 0.126461\tvalid_1's binary_logloss: 0.18683\n",
      "[4000]\ttraining's binary_logloss: 0.125101\tvalid_1's binary_logloss: 0.186446\n",
      "[4100]\ttraining's binary_logloss: 0.12375\tvalid_1's binary_logloss: 0.186069\n",
      "[4200]\ttraining's binary_logloss: 0.122456\tvalid_1's binary_logloss: 0.185732\n",
      "[4300]\ttraining's binary_logloss: 0.121191\tvalid_1's binary_logloss: 0.185382\n",
      "[4400]\ttraining's binary_logloss: 0.119961\tvalid_1's binary_logloss: 0.185042\n",
      "[4500]\ttraining's binary_logloss: 0.118749\tvalid_1's binary_logloss: 0.18475\n",
      "[4600]\ttraining's binary_logloss: 0.117552\tvalid_1's binary_logloss: 0.184453\n",
      "[4700]\ttraining's binary_logloss: 0.1164\tvalid_1's binary_logloss: 0.184147\n",
      "[4800]\ttraining's binary_logloss: 0.115237\tvalid_1's binary_logloss: 0.18382\n",
      "[4900]\ttraining's binary_logloss: 0.114129\tvalid_1's binary_logloss: 0.183576\n",
      "[5000]\ttraining's binary_logloss: 0.112977\tvalid_1's binary_logloss: 0.183257\n",
      "[5100]\ttraining's binary_logloss: 0.111889\tvalid_1's binary_logloss: 0.183074\n",
      "[5200]\ttraining's binary_logloss: 0.11086\tvalid_1's binary_logloss: 0.182872\n",
      "[5300]\ttraining's binary_logloss: 0.109785\tvalid_1's binary_logloss: 0.182626\n",
      "[5400]\ttraining's binary_logloss: 0.108756\tvalid_1's binary_logloss: 0.182353\n",
      "[5500]\ttraining's binary_logloss: 0.107742\tvalid_1's binary_logloss: 0.182115\n",
      "[5600]\ttraining's binary_logloss: 0.106738\tvalid_1's binary_logloss: 0.181904\n",
      "[5700]\ttraining's binary_logloss: 0.105758\tvalid_1's binary_logloss: 0.181647\n",
      "[5800]\ttraining's binary_logloss: 0.104798\tvalid_1's binary_logloss: 0.181453\n",
      "[5900]\ttraining's binary_logloss: 0.103848\tvalid_1's binary_logloss: 0.181216\n",
      "[6000]\ttraining's binary_logloss: 0.102912\tvalid_1's binary_logloss: 0.181084\n",
      "[6100]\ttraining's binary_logloss: 0.101995\tvalid_1's binary_logloss: 0.180891\n",
      "[6200]\ttraining's binary_logloss: 0.101074\tvalid_1's binary_logloss: 0.180674\n",
      "[6300]\ttraining's binary_logloss: 0.100144\tvalid_1's binary_logloss: 0.180494\n",
      "[6400]\ttraining's binary_logloss: 0.0992483\tvalid_1's binary_logloss: 0.180318\n",
      "[6500]\ttraining's binary_logloss: 0.0983635\tvalid_1's binary_logloss: 0.180186\n",
      "[6600]\ttraining's binary_logloss: 0.0974958\tvalid_1's binary_logloss: 0.180046\n",
      "[6700]\ttraining's binary_logloss: 0.0966608\tvalid_1's binary_logloss: 0.179935\n",
      "[6800]\ttraining's binary_logloss: 0.095827\tvalid_1's binary_logloss: 0.179837\n",
      "[6900]\ttraining's binary_logloss: 0.0950178\tvalid_1's binary_logloss: 0.179695\n",
      "[7000]\ttraining's binary_logloss: 0.0942265\tvalid_1's binary_logloss: 0.179581\n",
      "[7100]\ttraining's binary_logloss: 0.0934302\tvalid_1's binary_logloss: 0.179428\n",
      "[7200]\ttraining's binary_logloss: 0.0926457\tvalid_1's binary_logloss: 0.179346\n",
      "[7300]\ttraining's binary_logloss: 0.0919046\tvalid_1's binary_logloss: 0.179217\n",
      "[7400]\ttraining's binary_logloss: 0.0911405\tvalid_1's binary_logloss: 0.17915\n",
      "[7500]\ttraining's binary_logloss: 0.0903946\tvalid_1's binary_logloss: 0.179047\n",
      "[7600]\ttraining's binary_logloss: 0.0896358\tvalid_1's binary_logloss: 0.178942\n",
      "[7700]\ttraining's binary_logloss: 0.0889144\tvalid_1's binary_logloss: 0.17882\n",
      "[7800]\ttraining's binary_logloss: 0.0881872\tvalid_1's binary_logloss: 0.17873\n",
      "[7900]\ttraining's binary_logloss: 0.0874511\tvalid_1's binary_logloss: 0.178579\n",
      "[8000]\ttraining's binary_logloss: 0.0867703\tvalid_1's binary_logloss: 0.178486\n",
      "[8100]\ttraining's binary_logloss: 0.086092\tvalid_1's binary_logloss: 0.178417\n",
      "[8200]\ttraining's binary_logloss: 0.0853973\tvalid_1's binary_logloss: 0.17837\n",
      "[8300]\ttraining's binary_logloss: 0.0847262\tvalid_1's binary_logloss: 0.178288\n",
      "[8400]\ttraining's binary_logloss: 0.084081\tvalid_1's binary_logloss: 0.178323\n",
      "Early stopping, best iteration is:\n",
      "[8308]\ttraining's binary_logloss: 0.0846763\tvalid_1's binary_logloss: 0.178284\n",
      "Train F1:  0.6991033233966172\n",
      "Val F1 0.5086585328933426\n",
      "Fold 4\n",
      "(2003690, 1536) (500937, 1536)\n",
      "training PCA..\n",
      "(2003690, 100) (500937, 100)\n",
      "Final Shape (2003690, 124) (500937, 124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.241807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.238723\tvalid_1's binary_logloss: 0.246031\n",
      "[200]\ttraining's binary_logloss: 0.224301\tvalid_1's binary_logloss: 0.234465\n",
      "[300]\ttraining's binary_logloss: 0.216372\tvalid_1's binary_logloss: 0.229147\n",
      "[400]\ttraining's binary_logloss: 0.210309\tvalid_1's binary_logloss: 0.225669\n",
      "[500]\ttraining's binary_logloss: 0.2052\tvalid_1's binary_logloss: 0.222844\n",
      "[600]\ttraining's binary_logloss: 0.200451\tvalid_1's binary_logloss: 0.220389\n",
      "[700]\ttraining's binary_logloss: 0.196107\tvalid_1's binary_logloss: 0.218185\n",
      "[800]\ttraining's binary_logloss: 0.192177\tvalid_1's binary_logloss: 0.216247\n",
      "[900]\ttraining's binary_logloss: 0.188534\tvalid_1's binary_logloss: 0.214517\n",
      "[1000]\ttraining's binary_logloss: 0.185278\tvalid_1's binary_logloss: 0.213018\n",
      "[1100]\ttraining's binary_logloss: 0.182025\tvalid_1's binary_logloss: 0.211543\n",
      "[1200]\ttraining's binary_logloss: 0.178989\tvalid_1's binary_logloss: 0.210159\n",
      "[1300]\ttraining's binary_logloss: 0.176031\tvalid_1's binary_logloss: 0.208806\n",
      "[1400]\ttraining's binary_logloss: 0.17325\tvalid_1's binary_logloss: 0.207662\n",
      "[1500]\ttraining's binary_logloss: 0.170486\tvalid_1's binary_logloss: 0.2065\n",
      "[1600]\ttraining's binary_logloss: 0.167907\tvalid_1's binary_logloss: 0.205454\n",
      "[1700]\ttraining's binary_logloss: 0.165373\tvalid_1's binary_logloss: 0.204388\n",
      "[1800]\ttraining's binary_logloss: 0.162988\tvalid_1's binary_logloss: 0.203382\n",
      "[1900]\ttraining's binary_logloss: 0.160472\tvalid_1's binary_logloss: 0.202385\n",
      "[2000]\ttraining's binary_logloss: 0.158255\tvalid_1's binary_logloss: 0.201545\n",
      "[2100]\ttraining's binary_logloss: 0.15607\tvalid_1's binary_logloss: 0.200624\n",
      "[2200]\ttraining's binary_logloss: 0.153959\tvalid_1's binary_logloss: 0.199839\n",
      "[2300]\ttraining's binary_logloss: 0.151925\tvalid_1's binary_logloss: 0.199094\n",
      "[2400]\ttraining's binary_logloss: 0.149953\tvalid_1's binary_logloss: 0.198387\n",
      "[2500]\ttraining's binary_logloss: 0.148066\tvalid_1's binary_logloss: 0.197646\n",
      "[2600]\ttraining's binary_logloss: 0.146151\tvalid_1's binary_logloss: 0.196931\n",
      "[2700]\ttraining's binary_logloss: 0.144283\tvalid_1's binary_logloss: 0.196279\n",
      "[2800]\ttraining's binary_logloss: 0.142521\tvalid_1's binary_logloss: 0.195652\n",
      "[2900]\ttraining's binary_logloss: 0.140785\tvalid_1's binary_logloss: 0.195046\n",
      "[3000]\ttraining's binary_logloss: 0.139052\tvalid_1's binary_logloss: 0.194477\n",
      "[3100]\ttraining's binary_logloss: 0.137394\tvalid_1's binary_logloss: 0.193892\n",
      "[3200]\ttraining's binary_logloss: 0.135772\tvalid_1's binary_logloss: 0.193341\n",
      "[3300]\ttraining's binary_logloss: 0.134132\tvalid_1's binary_logloss: 0.192764\n",
      "[3400]\ttraining's binary_logloss: 0.132602\tvalid_1's binary_logloss: 0.19232\n",
      "[3500]\ttraining's binary_logloss: 0.13114\tvalid_1's binary_logloss: 0.191909\n",
      "[3600]\ttraining's binary_logloss: 0.129707\tvalid_1's binary_logloss: 0.191422\n",
      "[3700]\ttraining's binary_logloss: 0.128295\tvalid_1's binary_logloss: 0.190988\n",
      "[3800]\ttraining's binary_logloss: 0.12686\tvalid_1's binary_logloss: 0.19055\n",
      "[3900]\ttraining's binary_logloss: 0.125491\tvalid_1's binary_logloss: 0.190091\n",
      "[4000]\ttraining's binary_logloss: 0.124142\tvalid_1's binary_logloss: 0.189687\n",
      "[4100]\ttraining's binary_logloss: 0.122839\tvalid_1's binary_logloss: 0.189456\n",
      "[4200]\ttraining's binary_logloss: 0.121545\tvalid_1's binary_logloss: 0.189165\n",
      "[4300]\ttraining's binary_logloss: 0.120232\tvalid_1's binary_logloss: 0.188804\n",
      "[4400]\ttraining's binary_logloss: 0.119017\tvalid_1's binary_logloss: 0.188501\n",
      "[4500]\ttraining's binary_logloss: 0.1178\tvalid_1's binary_logloss: 0.188145\n",
      "[4600]\ttraining's binary_logloss: 0.116644\tvalid_1's binary_logloss: 0.187838\n",
      "[4700]\ttraining's binary_logloss: 0.115496\tvalid_1's binary_logloss: 0.187527\n",
      "[4800]\ttraining's binary_logloss: 0.114366\tvalid_1's binary_logloss: 0.187245\n",
      "[4900]\ttraining's binary_logloss: 0.11327\tvalid_1's binary_logloss: 0.186958\n",
      "[5000]\ttraining's binary_logloss: 0.112148\tvalid_1's binary_logloss: 0.186694\n",
      "[5100]\ttraining's binary_logloss: 0.111095\tvalid_1's binary_logloss: 0.186449\n",
      "[5200]\ttraining's binary_logloss: 0.110014\tvalid_1's binary_logloss: 0.18622\n",
      "[5300]\ttraining's binary_logloss: 0.108935\tvalid_1's binary_logloss: 0.18597\n",
      "[5400]\ttraining's binary_logloss: 0.107958\tvalid_1's binary_logloss: 0.18572\n",
      "[5500]\ttraining's binary_logloss: 0.106935\tvalid_1's binary_logloss: 0.185471\n",
      "[5600]\ttraining's binary_logloss: 0.105926\tvalid_1's binary_logloss: 0.185254\n",
      "[5700]\ttraining's binary_logloss: 0.104965\tvalid_1's binary_logloss: 0.185139\n",
      "[5800]\ttraining's binary_logloss: 0.104002\tvalid_1's binary_logloss: 0.184948\n",
      "[5900]\ttraining's binary_logloss: 0.103094\tvalid_1's binary_logloss: 0.184761\n",
      "[6000]\ttraining's binary_logloss: 0.102155\tvalid_1's binary_logloss: 0.1846\n",
      "[6100]\ttraining's binary_logloss: 0.101226\tvalid_1's binary_logloss: 0.184437\n",
      "[6200]\ttraining's binary_logloss: 0.100345\tvalid_1's binary_logloss: 0.184248\n",
      "[6300]\ttraining's binary_logloss: 0.0994635\tvalid_1's binary_logloss: 0.184114\n",
      "[6400]\ttraining's binary_logloss: 0.098597\tvalid_1's binary_logloss: 0.183961\n",
      "[6500]\ttraining's binary_logloss: 0.0977274\tvalid_1's binary_logloss: 0.183774\n",
      "[6600]\ttraining's binary_logloss: 0.0968992\tvalid_1's binary_logloss: 0.183628\n",
      "[6700]\ttraining's binary_logloss: 0.0960745\tvalid_1's binary_logloss: 0.183496\n",
      "[6800]\ttraining's binary_logloss: 0.0952486\tvalid_1's binary_logloss: 0.183402\n",
      "[6900]\ttraining's binary_logloss: 0.0944338\tvalid_1's binary_logloss: 0.183288\n",
      "[7000]\ttraining's binary_logloss: 0.0936312\tvalid_1's binary_logloss: 0.183203\n",
      "[7100]\ttraining's binary_logloss: 0.0928609\tvalid_1's binary_logloss: 0.183079\n",
      "[7200]\ttraining's binary_logloss: 0.0921059\tvalid_1's binary_logloss: 0.182968\n",
      "[7300]\ttraining's binary_logloss: 0.0913588\tvalid_1's binary_logloss: 0.18288\n",
      "[7400]\ttraining's binary_logloss: 0.090564\tvalid_1's binary_logloss: 0.182725\n",
      "[7500]\ttraining's binary_logloss: 0.0898341\tvalid_1's binary_logloss: 0.18263\n",
      "[7600]\ttraining's binary_logloss: 0.0891352\tvalid_1's binary_logloss: 0.182538\n",
      "[7700]\ttraining's binary_logloss: 0.0884185\tvalid_1's binary_logloss: 0.182417\n",
      "[7800]\ttraining's binary_logloss: 0.0876943\tvalid_1's binary_logloss: 0.182313\n",
      "[7900]\ttraining's binary_logloss: 0.0870001\tvalid_1's binary_logloss: 0.182246\n",
      "[8000]\ttraining's binary_logloss: 0.0863275\tvalid_1's binary_logloss: 0.18212\n",
      "[8100]\ttraining's binary_logloss: 0.0856779\tvalid_1's binary_logloss: 0.182038\n",
      "[8200]\ttraining's binary_logloss: 0.0850257\tvalid_1's binary_logloss: 0.181979\n",
      "[8300]\ttraining's binary_logloss: 0.0843795\tvalid_1's binary_logloss: 0.181913\n",
      "[8400]\ttraining's binary_logloss: 0.0837541\tvalid_1's binary_logloss: 0.181866\n",
      "[8500]\ttraining's binary_logloss: 0.0831116\tvalid_1's binary_logloss: 0.181863\n",
      "[8600]\ttraining's binary_logloss: 0.0824859\tvalid_1's binary_logloss: 0.181812\n",
      "[8700]\ttraining's binary_logloss: 0.0818514\tvalid_1's binary_logloss: 0.181747\n",
      "[8800]\ttraining's binary_logloss: 0.0812379\tvalid_1's binary_logloss: 0.181653\n",
      "[8900]\ttraining's binary_logloss: 0.080614\tvalid_1's binary_logloss: 0.181585\n",
      "[9000]\ttraining's binary_logloss: 0.0800009\tvalid_1's binary_logloss: 0.181571\n",
      "[9100]\ttraining's binary_logloss: 0.0794061\tvalid_1's binary_logloss: 0.181511\n",
      "[9200]\ttraining's binary_logloss: 0.0788058\tvalid_1's binary_logloss: 0.181447\n",
      "[9300]\ttraining's binary_logloss: 0.0782259\tvalid_1's binary_logloss: 0.181447\n",
      "Early stopping, best iteration is:\n",
      "[9266]\ttraining's binary_logloss: 0.0784257\tvalid_1's binary_logloss: 0.181426\n",
      "Train F1:  0.7192684573369066\n",
      "Val F1 0.5166727627407949\n"
     ]
    }
   ],
   "source": [
    "thresh = 0.15\n",
    "PCA_COMP = 100\n",
    "f1_errs = []\n",
    "pca_models = []\n",
    "lbg_models = []\n",
    "for fold, (train_index, val_index) in enumerate(group_kfold.split(X, y, groups=groups)):\n",
    "    print(f\"Fold {fold}\")\n",
    "    X_train, X_val = X[X.index.isin(train_index)], X[X.index.isin(val_index)]\n",
    "    y_train, y_val = y[y.index.isin(train_index)], y[y.index.isin(val_index)]\n",
    "    X_embeds_train, X_embeds_val = X_embeds[train_index], X_embeds[val_index]\n",
    "    print(X_embeds_train.shape, X_embeds_val.shape)\n",
    "    print('training PCA..')\n",
    "    pca = PCA(n_components=PCA_COMP,random_state=1)\n",
    "    pca.fit(X_embeds_train)\n",
    "    pca_models.append(pca)\n",
    "    X_embeds_train,X_embeds_val = pca.transform(X_embeds_train),pca.transform(X_embeds_val)\n",
    "    print(X_embeds_train.shape, X_embeds_val.shape)\n",
    "    X_train = pd.concat([X_train.reset_index(drop=True),pd.DataFrame(X_embeds_train,columns=[f\"embed_{i}\" for i in range(1,PCA_COMP+1)])],axis=1).set_index(train_index)\n",
    "    X_val = pd.concat([X_val.reset_index(drop=True),pd.DataFrame(X_embeds_val,columns=[f\"embed_{i}\" for i in range(1,PCA_COMP+1)])],axis=1).set_index(val_index)\n",
    "    print(\"Final Shape\",X_train.shape,X_val.shape)\n",
    "    train_dataset = lgb.Dataset(data=X_train, label=y_train)\n",
    "    val_dataset = lgb.Dataset(data=X_val, label=y_val)\n",
    "    params = {'objective':'binary',\n",
    "              'n_estimators':10_000,\n",
    "              'learning_rate':0.1,\n",
    "              'subsample':0.8,\n",
    "              #'max_depth':8,\n",
    "              #'num_leaves':60,\n",
    "              'feature_fraction':0.7,\n",
    "              'scale_pos_weight':2,\n",
    "              'device_type':'cpu',\n",
    "              'random_state':1,\n",
    "              'verbosity':0\n",
    "             }\n",
    "    clf = lgb.train(\n",
    "                    params,\n",
    "                    train_set=train_dataset,\n",
    "                    valid_sets=[train_dataset, val_dataset],\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(stopping_rounds=100),\n",
    "                        lgb.log_evaluation(100)\n",
    "                    ]\n",
    "                )\n",
    "    lbg_models.append(clf)\n",
    "    train_pred = clf.predict(X_train)\n",
    "    val_pred = clf.predict(X_val)\n",
    "    print('Train F1: ',f1_score(y_train, (train_pred>thresh).astype(int)))\n",
    "    print('Val F1', f1_score(y_val, (val_pred>thresh).astype(int)))\n",
    "    \n",
    "    #if fold == 0:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a1b77231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBQklEQVR4nO3df1RU953/8RfyYwQqEwzlx0T8kTahGkh2F1pE2xITGXRVmuZszVmSObLHUns0GhfcbIibFtOo3dSQtNjY1uPGNJCS01p60mjJELtKKD9UCqcQXc1pNWoLkh8I/hwmeL9/5MtNRvw1hhmK9/k4h3My977nM5/7VuSVz2fuEGIYhiEAAAALGjPSEwAAABgpBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZBCEAAGBZYSM9gb93Fy5c0N/+9jeNGzdOISEhIz0dAABwDQzD0KlTp+RwODRmzOXXfQhCV/G3v/1NycnJIz0NAABwHY4dO6YJEyZc9vynCkLr16/X448/rkceeUTPPfecpI8S2Jo1a/Szn/1MPT09yszM1I9//GPdcccd5vM8Ho9WrVqlX/ziFzp37pzuvfdePf/88z4T7enp0YoVK/Tqq69KkvLy8lReXq6bbrrJrDl69KiWLVum3//+94qMjFR+fr42bNigiIgIs6a9vV0PP/yw9uzZo/Hjx2vJkiV64oknrnl1Z9y4cZI+amRMTMz1tuqSvF6v3G63nE6nwsPDh3VsfIw+Bwd9Dg76HBz0OTgC2ee+vj4lJyebP8cv57qD0N69e/Wzn/1Md955p8/xp59+WmVlZdq6datuv/12PfXUU8rJydHBgwfNyaxcuVK//e1vVVVVpZtvvlnFxcWaP3++WlpaFBoaKknKz8/X8ePHVVNTI0n61re+JZfLpd/+9reSpIGBAc2bN0+f/exnVV9fr/fff1+LFi2SYRgqLy83m5CTk6NZs2Zp7969OnTokAoKChQdHa3i4uJrus7BwBQTExOQIBQVFaWYmBi+0QKIPgcHfQ4O+hwc9Dk4gtHnqy58GNfh1KlTxm233WbU1tYa2dnZxiOPPGIYhmFcuHDBSExMNL7//e+btefPnzfsdrvxk5/8xDAMwzh58qQRHh5uVFVVmTV//etfjTFjxhg1NTWGYRjG/v37DUlGU1OTWdPY2GhIMv7v//7PMAzD2LFjhzFmzBjjr3/9q1nzi1/8wrDZbEZvb69hGIbx/PPPG3a73Th//rxZs379esPhcBgXLly4pmvt7e01JJljDqf+/n7jN7/5jdHf3z/sY+Nj9Dk46HNw0OfgoM/BEcg+X+vP7+taEVq2bJnmzZun2bNn66mnnjKPHz58WF1dXXI6neYxm82m7OxsNTQ0aMmSJWppaZHX6/WpcTgcSk1NVUNDg3Jzc9XY2Ci73a7MzEyzZvr06bLb7WpoaFBKSooaGxuVmpoqh8Nh1uTm5srj8ailpUWzZs1SY2OjsrOzZbPZfGpKSkp05MgRTZkyZci1eTweeTwe83FfX5+kj1Kr1+u9nnZd1uB4wz0ufNHn4KDPwUGfg4M+B0cg+3ytY/odhKqqqvTHP/5Re/fuHXKuq6tLkpSQkOBzPCEhQe+8845ZExERodjY2CE1g8/v6upSfHz8kPHj4+N9ai5+ndjYWEVERPjUTJ48ecjrDJ67VBBav3691qxZM+S42+1WVFTUkOPDoba2NiDjwhd9Dg76HBz0OTjoc3AEos9nz569pjq/gtCxY8f0yCOPyO12a+zYsZetu3g/zjCMq+7RXVxzqfrhqDEM47LPlaSSkhIVFRWZjwffbOV0OgPyHqHa2lrl5OSwBx1A9Dk46HNw0OfgoM/BEcg+D+7oXI1fQailpUXd3d1KT083jw0MDKiurk4bN27UwYMHJX202pKUlGTWdHd3mysxiYmJ6u/vV09Pj8+qUHd3t2bMmGHWnDhxYsjrv/vuuz7jNDc3+5zv6emR1+v1qRlcHfrk60hDV60G2Ww2n620QeHh4QH7Zgjk2PgYfQ4O+hwc9Dk46HNwBKLP1zqeX58sfe+996q9vV1tbW3mV0ZGhh588EG1tbXp1ltvVWJios8SV39/v3bv3m2GnPT0dIWHh/vUdHZ2qqOjw6zJyspSb2+v9uzZY9Y0Nzert7fXp6ajo0OdnZ1mjdvtls1mM4NaVlaW6urq1N/f71PjcDiGbJkBAADr8WtFaNy4cUpNTfU5Fh0drZtvvtk8vnLlSq1bt0633XabbrvtNq1bt05RUVHKz8+XJNntdi1evFjFxcW6+eabNX78eK1atUppaWmaPXu2JGnq1KmaM2eOCgsL9dOf/lTSR7fPz58/XykpKZIkp9OpadOmyeVy6Qc/+IE++OADrVq1SoWFheYWVn5+vtasWaOCggI9/vjjevvtt7Vu3Tp95zvf4VOiAQDA8H+y9KOPPqpz585p6dKl5gcqut1unw80evbZZxUWFqaFCxeaH6i4detW8zOEJKmyslIrVqww7y7Ly8vTxo0bzfOhoaHavn27li5dqpkzZ/p8oOIgu92u2tpaLVu2TBkZGYqNjVVRUZHPe4AAAIB1feogtGvXLp/HISEhKi0tVWlp6WWfM3bsWJWXl5sffHgp48ePV0VFxRVfe+LEiXrttdeuWJOWlqa6uror1gAAAGvit88DAADLIggBAADLIggBAADLIggBAADLIggBAADLGvbb5+G/1NLX5RkYPZ9rdOT780Z6CgAADAtWhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGX5FYQ2bdqkO++8UzExMYqJiVFWVpZ+97vfmecLCgoUEhLi8zV9+nSfMTwej5YvX664uDhFR0crLy9Px48f96np6emRy+WS3W6X3W6Xy+XSyZMnfWqOHj2qBQsWKDo6WnFxcVqxYoX6+/t9atrb25Wdna3IyEjdcsstevLJJ2UYhj+XDAAAbmB+BaEJEybo+9//vvbt26d9+/bpnnvu0de+9jW99dZbZs2cOXPU2dlpfu3YscNnjJUrV6q6ulpVVVWqr6/X6dOnNX/+fA0MDJg1+fn5amtrU01NjWpqatTW1iaXy2WeHxgY0Lx583TmzBnV19erqqpK27ZtU3FxsVnT19ennJwcORwO7d27V+Xl5dqwYYPKysr8bhIAALgxhflTvGDBAp/Ha9eu1aZNm9TU1KQ77rhDkmSz2ZSYmHjJ5/f29mrLli166aWXNHv2bElSRUWFkpOT9cYbbyg3N1cHDhxQTU2NmpqalJmZKUnavHmzsrKydPDgQaWkpMjtdmv//v06duyYHA6HJOmZZ55RQUGB1q5dq5iYGFVWVur8+fPaunWrbDabUlNTdejQIZWVlamoqEghISH+dQoAANxw/ApCnzQwMKBf/vKXOnPmjLKysszju3btUnx8vG666SZlZ2dr7dq1io+PlyS1tLTI6/XK6XSa9Q6HQ6mpqWpoaFBubq4aGxtlt9vNECRJ06dPl91uV0NDg1JSUtTY2KjU1FQzBElSbm6uPB6PWlpaNGvWLDU2Nio7O1s2m82npqSkREeOHNGUKVMueV0ej0cej8d83NfXJ0nyer3yer3X265LGhzPNmZ0bdcNdx8CbXC+o23eow19Dg76HBz0OTgC2edrHdPvINTe3q6srCydP39en/nMZ1RdXa1p06ZJkubOnatvfOMbmjRpkg4fPqwnnnhC99xzj1paWmSz2dTV1aWIiAjFxsb6jJmQkKCuri5JUldXlxmcPik+Pt6nJiEhwed8bGysIiIifGomT5485HUGz10uCK1fv15r1qwZctztdisqKupq7bku38u4EJBxA+Xi7c7Rora2dqSnYAn0OTjoc3DQ5+AIRJ/Pnj17TXV+B6GUlBS1tbXp5MmT2rZtmxYtWqTdu3dr2rRpeuCBB8y61NRUZWRkaNKkSdq+fbvuv//+y45pGIbPVtWltq2Go2bwjdJX2hYrKSlRUVGR+bivr0/JyclyOp2KiYm57POuh9frVW1trZ7YN0aeC6Nnq66jNHekp+CXwT7n5OQoPDx8pKdzw6LPwUGfg4M+B0cg+zy4o3M1fgehiIgIff7zn5ckZWRkaO/evfrhD3+on/70p0Nqk5KSNGnSJL399tuSpMTERPX396unp8dnVai7u1szZswwa06cODFkrHfffddc0UlMTFRzc7PP+Z6eHnm9Xp+awdWhT76OpCGrSZ9ks9l8ttMGhYeHB+ybwXMhRJ6B0ROERus/CoH8M8TH6HNw0OfgoM/BEYg+X+t4n/pzhAzD8HlPzSe9//77OnbsmJKSkiRJ6enpCg8P91kC6+zsVEdHhxmEsrKy1Nvbqz179pg1zc3N6u3t9anp6OhQZ2enWeN2u2Wz2ZSenm7W1NXV+dxS73a75XA4hmyZAQAAa/IrCD3++ON68803deTIEbW3t2v16tXatWuXHnzwQZ0+fVqrVq1SY2Ojjhw5ol27dmnBggWKi4vT17/+dUmS3W7X4sWLVVxcrJ07d6q1tVUPPfSQ0tLSzLvIpk6dqjlz5qiwsFBNTU1qampSYWGh5s+fr5SUFEmS0+nUtGnT5HK51Nraqp07d2rVqlUqLCw0t6/y8/Nls9lUUFCgjo4OVVdXa926ddwxBgAATH5tjZ04cUIul0udnZ2y2+268847VVNTo5ycHJ07d07t7e36+c9/rpMnTyopKUmzZs3SK6+8onHjxpljPPvsswoLC9PChQt17tw53Xvvvdq6datCQ0PNmsrKSq1YscK8uywvL08bN240z4eGhmr79u1aunSpZs6cqcjISOXn52vDhg1mjd1uV21trZYtW6aMjAzFxsaqqKjI5/0/AADA2vwKQlu2bLnsucjISL3++utXHWPs2LEqLy9XeXn5ZWvGjx+vioqKK44zceJEvfbaa1esSUtLU11d3VXnBAAArInfNQYAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACyLIAQAACzLryC0adMm3XnnnYqJiVFMTIyysrL0u9/9zjxvGIZKS0vlcDgUGRmpu+++W2+99ZbPGB6PR8uXL1dcXJyio6OVl5en48eP+9T09PTI5XLJbrfLbrfL5XLp5MmTPjVHjx7VggULFB0drbi4OK1YsUL9/f0+Ne3t7crOzlZkZKRuueUWPfnkkzIMw59LBgAANzC/gtCECRP0/e9/X/v27dO+fft0zz336Gtf+5oZdp5++mmVlZVp48aN2rt3rxITE5WTk6NTp06ZY6xcuVLV1dWqqqpSfX29Tp8+rfnz52tgYMCsyc/PV1tbm2pqalRTU6O2tja5XC7z/MDAgObNm6czZ86ovr5eVVVV2rZtm4qLi82avr4+5eTkyOFwaO/evSovL9eGDRtUVlZ23c0CAAA3ljB/ihcsWODzeO3atdq0aZOampo0bdo0Pffcc1q9erXuv/9+SdKLL76ohIQEvfzyy1qyZIl6e3u1ZcsWvfTSS5o9e7YkqaKiQsnJyXrjjTeUm5urAwcOqKamRk1NTcrMzJQkbd68WVlZWTp48KBSUlLkdru1f/9+HTt2TA6HQ5L0zDPPqKCgQGvXrlVMTIwqKyt1/vx5bd26VTabTampqTp06JDKyspUVFSkkJCQT908AAAwuvkVhD5pYGBAv/zlL3XmzBllZWXp8OHD6urqktPpNGtsNpuys7PV0NCgJUuWqKWlRV6v16fG4XAoNTVVDQ0Nys3NVWNjo+x2uxmCJGn69Omy2+1qaGhQSkqKGhsblZqaaoYgScrNzZXH41FLS4tmzZqlxsZGZWdny2az+dSUlJToyJEjmjJlyiWvy+PxyOPxmI/7+vokSV6vV16v93rbdUmD49nGjK7tuuHuQ6ANzne0zXu0oc/BQZ+Dgz4HRyD7fK1j+h2E2tvblZWVpfPnz+szn/mMqqurNW3aNDU0NEiSEhISfOoTEhL0zjvvSJK6uroUERGh2NjYITVdXV1mTXx8/JDXjY+P96m5+HViY2MVERHhUzN58uQhrzN47nJBaP369VqzZs2Q4263W1FRUZd8zqf1vYwLARk3UHbs2DHSU7gutbW1Iz0FS6DPwUGfg4M+B0cg+nz27NlrqvM7CKWkpKitrU0nT57Utm3btGjRIu3evds8f/GWk2EYV92GurjmUvXDUTP4RukrzaekpERFRUXm476+PiUnJ8vpdComJuaK1+Evr9er2tpaPbFvjDwXRs9WXUdp7khPwS+Dfc7JyVF4ePhIT+eGRZ+Dgz4HB30OjkD2eXBH52r8DkIRERH6/Oc/L0nKyMjQ3r179cMf/lD/+Z//Kemj1ZakpCSzvru721yJSUxMVH9/v3p6enxWhbq7uzVjxgyz5sSJE0Ne99133/UZp7m52ed8T0+PvF6vT83g6tAnX0caumr1STabzWc7bVB4eHjAvhk8F0LkGRg9QWi0/qMQyD9DfIw+Bwd9Dg76HByB6PO1jvepP0fIMAx5PB5NmTJFiYmJPstb/f392r17txly0tPTFR4e7lPT2dmpjo4OsyYrK0u9vb3as2ePWdPc3Kze3l6fmo6ODnV2dpo1brdbNptN6enpZk1dXZ3PLfVut1sOh2PIlhkAALAmv4LQ448/rjfffFNHjhxRe3u7Vq9erV27dunBBx9USEiIVq5cqXXr1qm6ulodHR0qKChQVFSU8vPzJUl2u12LFy9WcXGxdu7cqdbWVj300ENKS0sz7yKbOnWq5syZo8LCQjU1NampqUmFhYWaP3++UlJSJElOp1PTpk2Ty+VSa2urdu7cqVWrVqmwsNDcvsrPz5fNZlNBQYE6OjpUXV2tdevWcccYAAAw+bU1duLECblcLnV2dsput+vOO+9UTU2NcnJyJEmPPvqozp07p6VLl6qnp0eZmZlyu90aN26cOcazzz6rsLAwLVy4UOfOndO9996rrVu3KjQ01KyprKzUihUrzLvL8vLytHHjRvN8aGiotm/frqVLl2rmzJmKjIxUfn6+NmzYYNbY7XbV1tZq2bJlysjIUGxsrIqKinze/wMAAKzNryC0ZcuWK54PCQlRaWmpSktLL1szduxYlZeXq7y8/LI148ePV0VFxRVfa+LEiXrttdeuWJOWlqa6uror1gAAAOvid40BAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBAADL8isIrV+/Xl/84hc1btw4xcfH67777tPBgwd9agoKChQSEuLzNX36dJ8aj8ej5cuXKy4uTtHR0crLy9Px48d9anp6euRyuWS322W32+VyuXTy5EmfmqNHj2rBggWKjo5WXFycVqxYof7+fp+a9vZ2ZWdnKzIyUrfccouefPJJGYbhz2UDAIAblF9BaPfu3Vq2bJmamppUW1urDz/8UE6nU2fOnPGpmzNnjjo7O82vHTt2+JxfuXKlqqurVVVVpfr6ep0+fVrz58/XwMCAWZOfn6+2tjbV1NSopqZGbW1tcrlc5vmBgQHNmzdPZ86cUX19vaqqqrRt2zYVFxebNX19fcrJyZHD4dDevXtVXl6uDRs2qKyszK8mAQCAG1OYP8U1NTU+j1944QXFx8erpaVFX/3qV83jNptNiYmJlxyjt7dXW7Zs0UsvvaTZs2dLkioqKpScnKw33nhDubm5OnDggGpqatTU1KTMzExJ0ubNm5WVlaWDBw8qJSVFbrdb+/fv17Fjx+RwOCRJzzzzjAoKCrR27VrFxMSosrJS58+f19atW2Wz2ZSamqpDhw6prKxMRUVFCgkJ8efyAQDADcavIHSx3t5eSdL48eN9ju/atUvx8fG66aablJ2drbVr1yo+Pl6S1NLSIq/XK6fTadY7HA6lpqaqoaFBubm5amxslN1uN0OQJE2fPl12u10NDQ1KSUlRY2OjUlNTzRAkSbm5ufJ4PGppadGsWbPU2Nio7Oxs2Ww2n5qSkhIdOXJEU6ZMGXJNHo9HHo/HfNzX1ydJ8nq98nq9n6ZdQwyOZxszurbqhrsPgTY439E279GGPgcHfQ4O+hwcgezztY553UHIMAwVFRXpy1/+slJTU83jc+fO1Te+8Q1NmjRJhw8f1hNPPKF77rlHLS0tstls6urqUkREhGJjY33GS0hIUFdXlySpq6vLDE6fFB8f71OTkJDgcz42NlYRERE+NZMnTx7yOoPnLhWE1q9frzVr1gw57na7FRUVdbW2XJfvZVwIyLiBcvFW52hRW1s70lOwBPocHPQ5OOhzcASiz2fPnr2muusOQg8//LD+9Kc/qb6+3uf4Aw88YP53amqqMjIyNGnSJG3fvl3333//ZcczDMNnq+pS21bDUTP4RunLbYuVlJSoqKjIfNzX16fk5GQ5nU7FxMRcdv7Xw+v1qra2Vk/sGyPPhdGzTddRmjvSU/DLYJ9zcnIUHh4+0tO5YdHn4KDPwUGfgyOQfR7c0bma6wpCy5cv16uvvqq6ujpNmDDhirVJSUmaNGmS3n77bUlSYmKi+vv71dPT47Mq1N3drRkzZpg1J06cGDLWu+++a67oJCYmqrm52ed8T0+PvF6vT83g6tAnX0fSkNWkQTabzWcrbVB4eHjAvhk8F0LkGRg9QWi0/qMQyD9DfIw+Bwd9Dg76HByB6PO1jufXXWOGYejhhx/Wr3/9a/3+97+/5NbSxd5//30dO3ZMSUlJkqT09HSFh4f7LIN1dnaqo6PDDEJZWVnq7e3Vnj17zJrm5mb19vb61HR0dKizs9OscbvdstlsSk9PN2vq6up8bql3u91yOBxDtswAAID1+BWEli1bpoqKCr388ssaN26curq61NXVpXPnzkmSTp8+rVWrVqmxsVFHjhzRrl27tGDBAsXFxenrX/+6JMlut2vx4sUqLi7Wzp071draqoceekhpaWnmXWRTp07VnDlzVFhYqKamJjU1NamwsFDz589XSkqKJMnpdGratGlyuVxqbW3Vzp07tWrVKhUWFppbWPn5+bLZbCooKFBHR4eqq6u1bt067hgDAACS/AxCmzZtUm9vr+6++24lJSWZX6+88ookKTQ0VO3t7fra176m22+/XYsWLdLtt9+uxsZGjRs3zhzn2Wef1X333aeFCxdq5syZioqK0m9/+1uFhoaaNZWVlUpLS5PT6ZTT6dSdd96pl156yTwfGhqq7du3a+zYsZo5c6YWLlyo++67Txs2bDBr7Ha7amtrdfz4cWVkZGjp0qUqKiryeQ8QAACwLr/eI3S1T2SOjIzU66+/ftVxxo4dq/LycpWXl1+2Zvz48aqoqLjiOBMnTtRrr712xZq0tDTV1dVddU4AAMB6+F1jAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsvwKQuvXr9cXv/hFjRs3TvHx8brvvvt08OBBnxrDMFRaWiqHw6HIyEjdfffdeuutt3xqPB6Pli9frri4OEVHRysvL0/Hjx/3qenp6ZHL5ZLdbpfdbpfL5dLJkyd9ao4ePaoFCxYoOjpacXFxWrFihfr7+31q2tvblZ2drcjISN1yyy168sknZRiGP5cNAABuUH4Fod27d2vZsmVqampSbW2tPvzwQzmdTp05c8asefrpp1VWVqaNGzdq7969SkxMVE5Ojk6dOmXWrFy5UtXV1aqqqlJ9fb1Onz6t+fPna2BgwKzJz89XW1ubampqVFNTo7a2NrlcLvP8wMCA5s2bpzNnzqi+vl5VVVXatm2biouLzZq+vj7l5OTI4XBo7969Ki8v14YNG1RWVnZdzQIAADeWMH+Ka2pqfB6/8MILio+PV0tLi7761a/KMAw999xzWr16te6//35J0osvvqiEhAS9/PLLWrJkiXp7e7Vlyxa99NJLmj17tiSpoqJCycnJeuONN5Sbm6sDBw6opqZGTU1NyszMlCRt3rxZWVlZOnjwoFJSUuR2u7V//34dO3ZMDodDkvTMM8+ooKBAa9euVUxMjCorK3X+/Hlt3bpVNptNqampOnTokMrKylRUVKSQkJBP3UAAADB6+RWELtbb2ytJGj9+vCTp8OHD6urqktPpNGtsNpuys7PV0NCgJUuWqKWlRV6v16fG4XAoNTVVDQ0Nys3NVWNjo+x2uxmCJGn69Omy2+1qaGhQSkqKGhsblZqaaoYgScrNzZXH41FLS4tmzZqlxsZGZWdny2az+dSUlJToyJEjmjJlypBr8ng88ng85uO+vj5Jktfrldfr/TTtGmJwPNuY0bVVN9x9CLTB+Y62eY829Dk46HNw0OfgCGSfr3XM6w5ChmGoqKhIX/7yl5WamipJ6urqkiQlJCT41CYkJOidd94xayIiIhQbGzukZvD5XV1dio+PH/Ka8fHxPjUXv05sbKwiIiJ8aiZPnjzkdQbPXSoIrV+/XmvWrBly3O12Kyoq6hKd+PS+l3EhIOMGyo4dO0Z6CteltrZ2pKdgCfQ5OOhzcNDn4AhEn8+ePXtNddcdhB5++GH96U9/Un19/ZBzF285GYZx1W2oi2suVT8cNYNvlL7cfEpKSlRUVGQ+7uvrU3JyspxOp2JiYq54Df7yer2qra3VE/vGyHNh9GzTdZTmjvQU/DLY55ycHIWHh4/0dG5Y9Dk46HNw0OfgCGSfB3d0rua6gtDy5cv16quvqq6uThMmTDCPJyYmSvpotSUpKck83t3dba7EJCYmqr+/Xz09PT6rQt3d3ZoxY4ZZc+LEiSGv++677/qM09zc7HO+p6dHXq/Xp2ZwdeiTryMNXbUaZLPZfLbSBoWHhwfsm8FzIUSegdEThEbrPwqB/DPEx+hzcNDn4KDPwRGIPl/reH7dNWYYhh5++GH9+te/1u9///shW0tTpkxRYmKizxJXf3+/du/ebYac9PR0hYeH+9R0dnaqo6PDrMnKylJvb6/27Nlj1jQ3N6u3t9enpqOjQ52dnWaN2+2WzWZTenq6WVNXV+dzS73b7ZbD4RiyZQYAAKzHryC0bNkyVVRU6OWXX9a4cePU1dWlrq4unTt3TtJH200rV67UunXrVF1drY6ODhUUFCgqKkr5+fmSJLvdrsWLF6u4uFg7d+5Ua2urHnroIaWlpZl3kU2dOlVz5sxRYWGhmpqa1NTUpMLCQs2fP18pKSmSJKfTqWnTpsnlcqm1tVU7d+7UqlWrVFhYaG5h5efny2azqaCgQB0dHaqurta6deu4YwwAAEjyc2ts06ZNkqS7777b5/gLL7yggoICSdKjjz6qc+fOaenSperp6VFmZqbcbrfGjRtn1j/77LMKCwvTwoULde7cOd17773aunWrQkNDzZrKykqtWLHCvLssLy9PGzduNM+HhoZq+/btWrp0qWbOnKnIyEjl5+drw4YNZo3dbldtba2WLVumjIwMxcbGqqioyOc9QAAAwLr8CkLX8onMISEhKi0tVWlp6WVrxo4dq/LycpWXl1+2Zvz48aqoqLjia02cOFGvvfbaFWvS0tJUV1d3xRoAAGBN/K4xAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWX4Hobq6Oi1YsEAOh0MhISH6zW9+43O+oKBAISEhPl/Tp0/3qfF4PFq+fLni4uIUHR2tvLw8HT9+3Kemp6dHLpdLdrtddrtdLpdLJ0+e9Kk5evSoFixYoOjoaMXFxWnFihXq7+/3qWlvb1d2drYiIyN1yy236Mknn5RhGP5eNgAAuAH5HYTOnDmju+66Sxs3brxszZw5c9TZ2Wl+7dixw+f8ypUrVV1draqqKtXX1+v06dOaP3++BgYGzJr8/Hy1tbWppqZGNTU1amtrk8vlMs8PDAxo3rx5OnPmjOrr61VVVaVt27apuLjYrOnr61NOTo4cDof27t2r8vJybdiwQWVlZf5eNgAAuAGF+fuEuXPnau7cuVessdlsSkxMvOS53t5ebdmyRS+99JJmz54tSaqoqFBycrLeeOMN5ebm6sCBA6qpqVFTU5MyMzMlSZs3b1ZWVpYOHjyolJQUud1u7d+/X8eOHZPD4ZAkPfPMMyooKNDatWsVExOjyspKnT9/Xlu3bpXNZlNqaqoOHTqksrIyFRUVKSQkxN/LBwAANxC/g9C12LVrl+Lj43XTTTcpOztba9euVXx8vCSppaVFXq9XTqfTrHc4HEpNTVVDQ4Nyc3PV2Ngou91uhiBJmj59uux2uxoaGpSSkqLGxkalpqaaIUiScnNz5fF41NLSolmzZqmxsVHZ2dmy2Ww+NSUlJTpy5IimTJkyZO4ej0cej8d83NfXJ0nyer3yer3D16T/P6Yk2caMrq264e5DoA3Od7TNe7Shz8FBn4ODPgdHIPt8rWMOexCaO3euvvGNb2jSpEk6fPiwnnjiCd1zzz1qaWmRzWZTV1eXIiIiFBsb6/O8hIQEdXV1SZK6urrM4PRJ8fHxPjUJCQk+52NjYxUREeFTM3ny5CGvM3juUkFo/fr1WrNmzZDjbrdbUVFR19gF/3wv40JAxg2Ui7c6R4va2tqRnoIl0OfgoM/BQZ+DIxB9Pnv27DXVDXsQeuCBB8z/Tk1NVUZGhiZNmqTt27fr/vvvv+zzDMPw2aq61LbVcNQMvlH6cttiJSUlKioqMh/39fUpOTlZTqdTMTExl53/9fB6vaqtrdUT+8bIc2H0bNN1lOaO9BT8MtjnnJwchYeHj/R0blj0OTjoc3DQ5+AIZJ8Hd3SuJiBbY5+UlJSkSZMm6e2335YkJSYmqr+/Xz09PT6rQt3d3ZoxY4ZZc+LEiSFjvfvuu+aKTmJiopqbm33O9/T0yOv1+tQMrg598nUkDVlNGmSz2Xy20gaFh4cH7JvBcyFEnoHRE4RG6z8KgfwzxMfoc3DQ5+Cgz8ERiD5f63gB/xyh999/X8eOHVNSUpIkKT09XeHh4T7LYJ2dnero6DCDUFZWlnp7e7Vnzx6zprm5Wb29vT41HR0d6uzsNGvcbrdsNpvS09PNmrq6Op9b6t1utxwOx5AtMwAAYD1+B6HTp0+rra1NbW1tkqTDhw+rra1NR48e1enTp7Vq1So1NjbqyJEj2rVrlxYsWKC4uDh9/etflyTZ7XYtXrxYxcXF2rlzp1pbW/XQQw8pLS3NvIts6tSpmjNnjgoLC9XU1KSmpiYVFhZq/vz5SklJkSQ5nU5NmzZNLpdLra2t2rlzp1atWqXCwkJzCys/P182m00FBQXq6OhQdXW11q1bxx1jAABA0nVsje3bt0+zZs0yHw++n2bRokXatGmT2tvb9fOf/1wnT55UUlKSZs2apVdeeUXjxo0zn/Pss88qLCxMCxcu1Llz53Tvvfdq69atCg0NNWsqKyu1YsUK8+6yvLw8n88uCg0N1fbt27V06VLNnDlTkZGRys/P14YNG8wau92u2tpaLVu2TBkZGYqNjVVRUZHPe4AAAIB1+R2E7r777it+MvPrr79+1THGjh2r8vJylZeXX7Zm/PjxqqiouOI4EydO1GuvvXbFmrS0NNXV1V11TgAAwHr4XWMAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCyCEIAAMCy/A5CdXV1WrBggRwOh0JCQvSb3/zG57xhGCotLZXD4VBkZKTuvvtuvfXWWz41Ho9Hy5cvV1xcnKKjo5WXl6fjx4/71PT09Mjlcslut8tut8vlcunkyZM+NUePHtWCBQsUHR2tuLg4rVixQv39/T417e3tys7OVmRkpG655RY9+eSTMgzD38sGAAA3IL+D0JkzZ3TXXXdp48aNlzz/9NNPq6ysTBs3btTevXuVmJionJwcnTp1yqxZuXKlqqurVVVVpfr6ep0+fVrz58/XwMCAWZOfn6+2tjbV1NSopqZGbW1tcrlc5vmBgQHNmzdPZ86cUX19vaqqqrRt2zYVFxebNX19fcrJyZHD4dDevXtVXl6uDRs2qKyszN/LBgAAN6Awf58wd+5czZ0795LnDMPQc889p9WrV+v++++XJL344otKSEjQyy+/rCVLlqi3t1dbtmzRSy+9pNmzZ0uSKioqlJycrDfeeEO5ubk6cOCAampq1NTUpMzMTEnS5s2blZWVpYMHDyolJUVut1v79+/XsWPH5HA4JEnPPPOMCgoKtHbtWsXExKiyslLnz5/X1q1bZbPZlJqaqkOHDqmsrExFRUUKCQm5rqYBAIAbg99B6EoOHz6srq4uOZ1O85jNZlN2drYaGhq0ZMkStbS0yOv1+tQ4HA6lpqaqoaFBubm5amxslN1uN0OQJE2fPl12u10NDQ1KSUlRY2OjUlNTzRAkSbm5ufJ4PGppadGsWbPU2Nio7Oxs2Ww2n5qSkhIdOXJEU6ZMGXINHo9HHo/HfNzX1ydJ8nq98nq9w9Oo/29wPNuY0bVVN9x9CLTB+Y62eY829Dk46HNw0OfgCGSfr3XMYQ1CXV1dkqSEhASf4wkJCXrnnXfMmoiICMXGxg6pGXx+V1eX4uPjh4wfHx/vU3Px68TGxioiIsKnZvLkyUNeZ/DcpYLQ+vXrtWbNmiHH3W63oqKiLn3hn9L3Mi4EZNxA2bFjx0hP4brU1taO9BQsgT4HB30ODvocHIHo89mzZ6+pbliD0KCLt5wMw7jqNtTFNZeqH46awTdKX24+JSUlKioqMh/39fUpOTlZTqdTMTExV7wGf3m9XtXW1uqJfWPkuTB6tuk6SnNHegp+GexzTk6OwsPDR3o6Nyz6HBz0OTjoc3AEss+DOzpXM6xBKDExUdJHqy1JSUnm8e7ubnMlJjExUf39/erp6fFZFeru7taMGTPMmhMnTgwZ/9133/UZp7m52ed8T0+PvF6vT83g6tAnX0caumo1yGaz+WylDQoPDw/YN4PnQog8A6MnCI3WfxQC+WeIj9Hn4KDPwUGfgyMQfb7W8Yb1c4SmTJmixMREnyWu/v5+7d692ww56enpCg8P96np7OxUR0eHWZOVlaXe3l7t2bPHrGlublZvb69PTUdHhzo7O80at9stm82m9PR0s6aurs7nlnq32y2HwzFkywwAAFiP30Ho9OnTamtrU1tbm6SP3iDd1tamo0ePKiQkRCtXrtS6detUXV2tjo4OFRQUKCoqSvn5+ZIku92uxYsXq7i4WDt37lRra6seeughpaWlmXeRTZ06VXPmzFFhYaGamprU1NSkwsJCzZ8/XykpKZIkp9OpadOmyeVyqbW1VTt37tSqVatUWFhobmHl5+fLZrOpoKBAHR0dqq6u1rp167hjDAAASLqOrbF9+/Zp1qxZ5uPB99MsWrRIW7du1aOPPqpz585p6dKl6unpUWZmptxut8aNG2c+59lnn1VYWJgWLlyoc+fO6d5779XWrVsVGhpq1lRWVmrFihXm3WV5eXk+n10UGhqq7du3a+nSpZo5c6YiIyOVn5+vDRs2mDV2u121tbVatmyZMjIyFBsbq6KiIp/3AAEAAOvyOwjdfffdV/xk5pCQEJWWlqq0tPSyNWPHjlV5ebnKy8svWzN+/HhVVFRccS4TJ07Ua6+9dsWatLQ01dXVXbEGAABYE79rDAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWBZBCAAAWNawB6HS0lKFhIT4fCUmJprnDcNQaWmpHA6HIiMjdffdd+utt97yGcPj8Wj58uWKi4tTdHS08vLydPz4cZ+anp4euVwu2e122e12uVwunTx50qfm6NGjWrBggaKjoxUXF6cVK1aov79/uC8ZAACMUgFZEbrjjjvU2dlpfrW3t5vnnn76aZWVlWnjxo3au3evEhMTlZOTo1OnTpk1K1euVHV1taqqqlRfX6/Tp09r/vz5GhgYMGvy8/PV1tammpoa1dTUqK2tTS6Xyzw/MDCgefPm6cyZM6qvr1dVVZW2bdum4uLiQFwyAAAYhcICMmhYmM8q0CDDMPTcc89p9erVuv/++yVJL774ohISEvTyyy9ryZIl6u3t1ZYtW/TSSy9p9uzZkqSKigolJyfrjTfeUG5urg4cOKCamho1NTUpMzNTkrR582ZlZWXp4MGDSklJkdvt1v79+3Xs2DE5HA5J0jPPPKOCggKtXbtWMTExgbh0AAAwigQkCL399ttyOByy2WzKzMzUunXrdOutt+rw4cPq6uqS0+k0a202m7Kzs9XQ0KAlS5aopaVFXq/Xp8bhcCg1NVUNDQ3Kzc1VY2Oj7Ha7GYIkafr06bLb7WpoaFBKSooaGxuVmppqhiBJys3NlcfjUUtLi2bNmnXJuXs8Hnk8HvNxX1+fJMnr9crr9Q5bjwbHlCTbGGNYxw204e5DoA3Od7TNe7Shz8FBn4ODPgdHIPt8rWMOexDKzMzUz3/+c91+++06ceKEnnrqKc2YMUNvvfWWurq6JEkJCQk+z0lISNA777wjSerq6lJERIRiY2OH1Aw+v6urS/Hx8UNeOz4+3qfm4teJjY1VRESEWXMp69ev15o1a4Ycd7vdioqKutrlX5fvZVwIyLiBsmPHjpGewnWpra0d6SlYAn0ODvocHPQ5OALR57Nnz15T3bAHoblz55r/nZaWpqysLH3uc5/Tiy++qOnTp0uSQkJCfJ5jGMaQYxe7uOZS9ddTc7GSkhIVFRWZj/v6+pScnCyn0zns22ler1e1tbV6Yt8YeS5c+fr/nnSU5o70FPwy2OecnByFh4eP9HRuWPQ5OOhzcNDn4Ahknwd3dK4mIFtjnxQdHa20tDS9/fbbuu+++yR9tFqTlJRk1nR3d5urN4mJierv71dPT4/PqlB3d7dmzJhh1pw4cWLIa7377rs+4zQ3N/uc7+npkdfrHbJS9Ek2m002m23I8fDw8IB9M3guhMgzMHqC0Gj9RyGQf4b4GH0ODvocHPQ5OALR52sdL+CfI+TxeHTgwAElJSVpypQpSkxM9FkC6+/v1+7du82Qk56ervDwcJ+azs5OdXR0mDVZWVnq7e3Vnj17zJrm5mb19vb61HR0dKizs9OscbvdstlsSk9PD+g1AwCA0WHYV4RWrVqlBQsWaOLEieru7tZTTz2lvr4+LVq0SCEhIVq5cqXWrVun2267TbfddpvWrVunqKgo5efnS5LsdrsWL16s4uJi3XzzzRo/frxWrVqltLQ08y6yqVOnas6cOSosLNRPf/pTSdK3vvUtzZ8/XykpKZIkp9OpadOmyeVy6Qc/+IE++OADrVq1SoWFhdwx9ilNfmz7SE/BL7ZQQ09/aaRnAQD4ezTsQej48eP613/9V7333nv67Gc/q+nTp6upqUmTJk2SJD366KM6d+6cli5dqp6eHmVmZsrtdmvcuHHmGM8++6zCwsK0cOFCnTt3Tvfee6+2bt2q0NBQs6ayslIrVqww7y7Ly8vTxo0bzfOhoaHavn27li5dqpkzZyoyMlL5+fnasGHDcF8yAAAYpYY9CFVVVV3xfEhIiEpLS1VaWnrZmrFjx6q8vFzl5eWXrRk/frwqKiqu+FoTJ07Ua6+9dsUaAABgXfyuMQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFlhIz0BIFhSS1+XZyBkpKdxzY58f95ITwEAbnisCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMsiCAEAAMvi9nng79Tkx7aP9BT8Ygs19PSXRnoWAOAfghAAADcI/gfKf2yNAQAAy2JFCMCw4hO8AYwmrAgBAADLYkUIgKWN1vdUsPIWHKOtz/CfJYLQ888/rx/84Afq7OzUHXfcoeeee05f+cpXRnpaAGAZozVw4sZ3w2+NvfLKK1q5cqVWr16t1tZWfeUrX9HcuXN19OjRkZ4aAAAYYTd8ECorK9PixYv1zW9+U1OnTtVzzz2n5ORkbdq0aaSnBgAARtgNvTXW39+vlpYWPfbYYz7HnU6nGhoaLvkcj8cjj8djPu7t7ZUkffDBB/J6vcM6P6/Xq7NnzyrMO0YDF9iDDpSwC4bOnr1AnwOMPgcHfQ4O+hwcg31+//33FR4ePqxjnzp1SpJkGMaV5zCsr/p35r333tPAwIASEhJ8jickJKirq+uSz1m/fr3WrFkz5PiUKVMCMkcER/5IT8Ai6HNw0OfgoM/BEeg+nzp1Sna7/bLnb+ggNCgkxDfNG4Yx5NigkpISFRUVmY8vXLigDz74QDfffPNln3O9+vr6lJycrGPHjikmJmZYx8bH6HNw0OfgoM/BQZ+DI5B9NgxDp06dksPhuGLdDR2E4uLiFBoaOmT1p7u7e8gq0SCbzSabzeZz7KabbgrUFCVJMTExfKMFAX0ODvocHPQ5OOhzcASqz1daCRp0Q79ZOiIiQunp6aqtrfU5XltbqxkzZozQrAAAwN+LG3pFSJKKiorkcrmUkZGhrKws/exnP9PRo0f17W9/e6SnBgAARtgNH4QeeOABvf/++3ryySfV2dmp1NRU7dixQ5MmTRrpqclms+m73/3ukK04DC/6HBz0OTjoc3DQ5+D4e+hziHG1+8oAAABuUDf0e4QAAACuhCAEAAAsiyAEAAAsiyAEAAAsiyAUQM8//7ymTJmisWPHKj09XW+++eYV63fv3q309HSNHTtWt956q37yk58Eaaajnz+9/vWvf62cnBx99rOfVUxMjLKysvT6668Hcbajl79/pwf94Q9/UFhYmP7hH/4hsBO8QfjbZ4/Ho9WrV2vSpEmy2Wz63Oc+p//5n/8J0mxHL3/7XFlZqbvuuktRUVFKSkrSv/3bv+n9998P0mxHp7q6Oi1YsEAOh0MhISH6zW9+c9XnBP1noYGAqKqqMsLDw43Nmzcb+/fvNx555BEjOjraeOeddy5Z/5e//MWIiooyHnnkEWP//v3G5s2bjfDwcONXv/pVkGc++vjb60ceecT47//+b2PPnj3GoUOHjJKSEiM8PNz44x//GOSZjy7+9nnQyZMnjVtvvdVwOp3GXXfdFZzJjmLX0+e8vDwjMzPTqK2tNQ4fPmw0Nzcbf/jDH4I469HH3z6/+eabxpgxY4wf/vCHxl/+8hfjzTffNO644w7jvvvuC/LMR5cdO3YYq1evNrZt22ZIMqqrq69YPxI/CwlCAfKlL33J+Pa3v+1z7Atf+ILx2GOPXbL+0UcfNb7whS/4HFuyZIkxffr0gM3xRuFvry9l2rRpxpo1a4Z7ajeU6+3zAw88YPzXf/2X8d3vfpcgdA387fPvfvc7w263G++//34wpnfD8LfPP/jBD4xbb73V59iPfvQjY8KECQGb443mWoLQSPwsZGssAPr7+9XS0iKn0+lz3Ol0qqGh4ZLPaWxsHFKfm5urffv2yev1Bmyuo9319PpiFy5c0KlTpzR+/PhATPGGcL19fuGFF/TnP/9Z3/3udwM9xRvC9fT51VdfVUZGhp5++mndcsstuv3227Vq1SqdO3cuGFMela6nzzNmzNDx48e1Y8cOGYahEydO6Fe/+pXmzZsXjClbxkj8LLzhP1l6JLz33nsaGBgY8otdExIShvwC2EFdXV2XrP/www/13nvvKSkpKWDzHc2up9cXe+aZZ3TmzBktXLgwEFO8IVxPn99++2099thjevPNNxUWxj811+J6+vyXv/xF9fX1Gjt2rKqrq/Xee+9p6dKl+uCDD3if0GVcT59nzJihyspKPfDAAzp//rw+/PBD5eXlqby8PBhTtoyR+FnIilAAhYSE+Dw2DGPIsavVX+o4hvK314N+8YtfqLS0VK+88ori4+MDNb0bxrX2eWBgQPn5+VqzZo1uv/32YE3vhuHP3+cLFy4oJCRElZWV+tKXvqR//ud/VllZmbZu3cqq0FX40+f9+/drxYoV+s53vqOWlhbV1NTo8OHD/N7KAAj2z0L+Ny0A4uLiFBoaOuT/LLq7u4ck3UGJiYmXrA8LC9PNN98csLmOdtfT60GvvPKKFi9erF/+8peaPXt2IKc56vnb51OnTmnfvn1qbW3Vww8/LOmjH9iGYSgsLExut1v33HNPUOY+mlzP3+ekpCTdcsststvt5rGpU6fKMAwdP35ct912W0DnPBpdT5/Xr1+vmTNn6j/+4z8kSXfeeaeio6P1la98RU899RSr9sNkJH4WsiIUABEREUpPT1dtba3P8draWs2YMeOSz8nKyhpS73a7lZGRofDw8IDNdbS7nl5LH60EFRQU6OWXX2aP/xr42+eYmBi1t7erra3N/Pr2t7+tlJQUtbW1KTMzM1hTH1Wu5+/zzJkz9be//U2nT582jx06dEhjxozRhAkTAjrf0ep6+nz27FmNGeP7IzM0NFTSxysW+PRG5GdhwN6GbXGDt2Zu2bLF2L9/v7Fy5UojOjraOHLkiGEYhvHYY48ZLpfLrB+8ZfDf//3fjf379xtbtmzh9vlr5G+vX375ZSMsLMz48Y9/bHR2dppfJ0+eHKlLGBX87fPFuGvs2vjb51OnThkTJkww/uVf/sV46623jN27dxu33Xab8c1vfnOkLmFU8LfPL7zwghEWFmY8//zzxp///Gejvr7eyMjIML70pS+N1CWMCqdOnTJaW1uN1tZWQ5JRVlZmtLa2mh9T8Pfws5AgFEA//vGPjUmTJhkRERHGP/3TPxm7d+82zy1atMjIzs72qd+1a5fxj//4j0ZERIQxefJkY9OmTUGe8ejlT6+zs7MNSUO+Fi1aFPyJjzL+/p3+JILQtfO3zwcOHDBmz55tREZGGhMmTDCKioqMs2fPBnnWo4+/ff7Rj35kTJs2zYiMjDSSkpKMBx980Dh+/HiQZz26/O///u8V/739e/hZGGIYrOkBAABr4j1CAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsv4ffTdTvSd2UfQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(val_pred).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af55e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3085</td>\n",
       "      <td>embed_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2901</td>\n",
       "      <td>embed_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2804</td>\n",
       "      <td>embed_72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2757</td>\n",
       "      <td>embed_78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2716</td>\n",
       "      <td>embed_100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2674</td>\n",
       "      <td>title_len2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2666</td>\n",
       "      <td>embed_96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2654</td>\n",
       "      <td>embed_84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2646</td>\n",
       "      <td>embed_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2633</td>\n",
       "      <td>embed_95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2619</td>\n",
       "      <td>embed_92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2616</td>\n",
       "      <td>embed_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2592</td>\n",
       "      <td>embed_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2591</td>\n",
       "      <td>embed_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2582</td>\n",
       "      <td>embed_98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2569</td>\n",
       "      <td>title_jaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2557</td>\n",
       "      <td>embed_73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2555</td>\n",
       "      <td>embed_68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2543</td>\n",
       "      <td>embed_81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2541</td>\n",
       "      <td>embed_69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2540</td>\n",
       "      <td>embed_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2538</td>\n",
       "      <td>embed_85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2537</td>\n",
       "      <td>embed_89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2535</td>\n",
       "      <td>embed_86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2535</td>\n",
       "      <td>embed_97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2530</td>\n",
       "      <td>embed_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2523</td>\n",
       "      <td>embed_87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2521</td>\n",
       "      <td>embed_79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2518</td>\n",
       "      <td>embed_76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2514</td>\n",
       "      <td>title_partialratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2512</td>\n",
       "      <td>embed_91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2509</td>\n",
       "      <td>embed_90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2497</td>\n",
       "      <td>embed_99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2478</td>\n",
       "      <td>embed_83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2475</td>\n",
       "      <td>embed_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2475</td>\n",
       "      <td>description_jaro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2466</td>\n",
       "      <td>embed_65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2456</td>\n",
       "      <td>title_seqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2456</td>\n",
       "      <td>embed_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2446</td>\n",
       "      <td>embed_80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2434</td>\n",
       "      <td>embed_77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2432</td>\n",
       "      <td>embed_63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2422</td>\n",
       "      <td>embed_74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2417</td>\n",
       "      <td>embed_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2405</td>\n",
       "      <td>embed_71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2399</td>\n",
       "      <td>embed_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2395</td>\n",
       "      <td>embed_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2395</td>\n",
       "      <td>embed_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2393</td>\n",
       "      <td>embed_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2393</td>\n",
       "      <td>embed_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2382</td>\n",
       "      <td>embed_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2375</td>\n",
       "      <td>embed_82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2368</td>\n",
       "      <td>embed_70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2359</td>\n",
       "      <td>embed_61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2354</td>\n",
       "      <td>embed_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2349</td>\n",
       "      <td>embed_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2349</td>\n",
       "      <td>embed_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2332</td>\n",
       "      <td>embed_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2330</td>\n",
       "      <td>embed_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2329</td>\n",
       "      <td>embed_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2328</td>\n",
       "      <td>embed_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2321</td>\n",
       "      <td>embed_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2321</td>\n",
       "      <td>embed_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2320</td>\n",
       "      <td>embed_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2318</td>\n",
       "      <td>embed_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2318</td>\n",
       "      <td>embed_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2315</td>\n",
       "      <td>embed_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2313</td>\n",
       "      <td>embed_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2313</td>\n",
       "      <td>embed_38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2311</td>\n",
       "      <td>embed_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2308</td>\n",
       "      <td>embed_33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2307</td>\n",
       "      <td>embed_67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2305</td>\n",
       "      <td>embed_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2301</td>\n",
       "      <td>embed_55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2296</td>\n",
       "      <td>embed_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2290</td>\n",
       "      <td>embed_36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2283</td>\n",
       "      <td>embed_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2282</td>\n",
       "      <td>embed_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2279</td>\n",
       "      <td>embed_46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2274</td>\n",
       "      <td>embed_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2267</td>\n",
       "      <td>embed_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2264</td>\n",
       "      <td>embed_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2261</td>\n",
       "      <td>embed_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2255</td>\n",
       "      <td>embed_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2252</td>\n",
       "      <td>description_len2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2252</td>\n",
       "      <td>embed_66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2251</td>\n",
       "      <td>embed_44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2246</td>\n",
       "      <td>embed_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2238</td>\n",
       "      <td>embed_49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2232</td>\n",
       "      <td>embed_32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2228</td>\n",
       "      <td>embed_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2227</td>\n",
       "      <td>embed_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2224</td>\n",
       "      <td>embed_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2219</td>\n",
       "      <td>embed_93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2206</td>\n",
       "      <td>embed_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2200</td>\n",
       "      <td>description_nleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2198</td>\n",
       "      <td>embed_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2197</td>\n",
       "      <td>embed_41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2189</td>\n",
       "      <td>embed_47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2180</td>\n",
       "      <td>embed_37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2161</td>\n",
       "      <td>embed_35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2154</td>\n",
       "      <td>embed_57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2150</td>\n",
       "      <td>embed_56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2145</td>\n",
       "      <td>embed_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2145</td>\n",
       "      <td>embed_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2127</td>\n",
       "      <td>embed_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2110</td>\n",
       "      <td>description_seqm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2071</td>\n",
       "      <td>embed_43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2028</td>\n",
       "      <td>description_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>description_partialratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1995</td>\n",
       "      <td>title_nleven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1995</td>\n",
       "      <td>description_len_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1994</td>\n",
       "      <td>title_wratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1902</td>\n",
       "      <td>description_leven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1831</td>\n",
       "      <td>title_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1703</td>\n",
       "      <td>title_leven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1669</td>\n",
       "      <td>title_len_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1595</td>\n",
       "      <td>description_wratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>content_description_isna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>topic_description_isna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>53</td>\n",
       "      <td>title_venn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>content_title_isna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>description_venn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>topic_title_isna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Value                   Feature\n",
       "25    3085                   embed_2\n",
       "28    2901                   embed_5\n",
       "95    2804                  embed_72\n",
       "101   2757                  embed_78\n",
       "123   2716                 embed_100\n",
       "21    2674                title_len2\n",
       "119   2666                  embed_96\n",
       "107   2654                  embed_84\n",
       "111   2646                  embed_88\n",
       "118   2633                  embed_95\n",
       "115   2619                  embed_92\n",
       "24    2616                   embed_1\n",
       "117   2592                  embed_94\n",
       "26    2591                   embed_3\n",
       "121   2582                  embed_98\n",
       "18    2569                title_jaro\n",
       "96    2557                  embed_73\n",
       "91    2555                  embed_68\n",
       "104   2543                  embed_81\n",
       "92    2541                  embed_69\n",
       "98    2540                  embed_75\n",
       "108   2538                  embed_85\n",
       "112   2537                  embed_89\n",
       "109   2535                  embed_86\n",
       "120   2535                  embed_97\n",
       "37    2530                  embed_14\n",
       "110   2523                  embed_87\n",
       "102   2521                  embed_79\n",
       "99    2518                  embed_76\n",
       "14    2514        title_partialratio\n",
       "114   2512                  embed_91\n",
       "113   2509                  embed_90\n",
       "122   2497                  embed_99\n",
       "106   2478                  embed_83\n",
       "43    2475                  embed_20\n",
       "8     2475          description_jaro\n",
       "88    2466                  embed_65\n",
       "16    2456                title_seqm\n",
       "35    2456                  embed_12\n",
       "103   2446                  embed_80\n",
       "100   2434                  embed_77\n",
       "86    2432                  embed_63\n",
       "97    2422                  embed_74\n",
       "46    2417                  embed_23\n",
       "94    2405                  embed_71\n",
       "31    2399                   embed_8\n",
       "48    2395                  embed_25\n",
       "44    2395                  embed_21\n",
       "77    2393                  embed_54\n",
       "29    2393                   embed_6\n",
       "27    2382                   embed_4\n",
       "105   2375                  embed_82\n",
       "93    2368                  embed_70\n",
       "84    2359                  embed_61\n",
       "49    2354                  embed_26\n",
       "50    2349                  embed_27\n",
       "39    2349                  embed_16\n",
       "63    2332                  embed_40\n",
       "87    2330                  embed_64\n",
       "30    2329                   embed_7\n",
       "57    2328                  embed_34\n",
       "62    2321                  embed_39\n",
       "45    2321                  embed_22\n",
       "40    2320                  embed_17\n",
       "82    2318                  embed_59\n",
       "47    2318                  embed_24\n",
       "85    2315                  embed_62\n",
       "83    2313                  embed_60\n",
       "61    2313                  embed_38\n",
       "38    2311                  embed_15\n",
       "56    2308                  embed_33\n",
       "90    2307                  embed_67\n",
       "41    2305                  embed_18\n",
       "78    2301                  embed_55\n",
       "74    2296                  embed_51\n",
       "59    2290                  embed_36\n",
       "51    2283                  embed_28\n",
       "53    2282                  embed_30\n",
       "69    2279                  embed_46\n",
       "68    2274                  embed_45\n",
       "52    2267                  embed_29\n",
       "76    2264                  embed_53\n",
       "81    2261                  embed_58\n",
       "32    2255                   embed_9\n",
       "11    2252          description_len2\n",
       "89    2252                  embed_66\n",
       "67    2251                  embed_44\n",
       "75    2246                  embed_52\n",
       "72    2238                  embed_49\n",
       "55    2232                  embed_32\n",
       "34    2228                  embed_11\n",
       "36    2227                  embed_13\n",
       "42    2224                  embed_19\n",
       "116   2219                  embed_93\n",
       "33    2206                  embed_10\n",
       "13    2200        description_nleven\n",
       "65    2198                  embed_42\n",
       "64    2197                  embed_41\n",
       "70    2189                  embed_47\n",
       "60    2180                  embed_37\n",
       "58    2161                  embed_35\n",
       "80    2154                  embed_57\n",
       "79    2150                  embed_56\n",
       "71    2145                  embed_48\n",
       "54    2145                  embed_31\n",
       "73    2127                  embed_50\n",
       "6     2110          description_seqm\n",
       "66    2071                  embed_43\n",
       "10    2028           description_len\n",
       "4     2019  description_partialratio\n",
       "23    1995              title_nleven\n",
       "12    1995      description_len_diff\n",
       "15    1994              title_wratio\n",
       "7     1902         description_leven\n",
       "20    1831                 title_len\n",
       "17    1703               title_leven\n",
       "22    1669            title_len_diff\n",
       "5     1595        description_wratio\n",
       "1      239  content_description_isna\n",
       "3      183    topic_description_isna\n",
       "19      53                title_venn\n",
       "0       32        content_title_isna\n",
       "9       16          description_venn\n",
       "2        0          topic_title_isna"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.DataFrame({'Value':clf.feature_importance(),'Feature':X_train.columns}).sort_values('Value',ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf2d092f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8934896496281904, 0.5844019240542233)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.4\n",
    "f1_score(y_train, (train_pred>thresh).astype(int)),f1_score(y_val, (val_pred>thresh).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5cbbea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(mode,pca_models=None,gbdt_models=None, embed_shape=100):\n",
    "    candidate_df = pd.read_parquet('data/candidates_50_train_7840.parquet')[['topics_ids','content_ids','target','fold']]\n",
    "    candidate_df = candidate_df[candidate_df.fold == 0]\n",
    "    print(\"Candidate Shape:\", candidate_df.shape)\n",
    "    X_embeds = np.load('data/features_50_val.npy')\n",
    "    candidate_df.columns = ['topic_id','content_id','target','fold']\n",
    "    topics = pd.read_csv('data/topics.csv')\n",
    "    content = pd.read_csv('data/content.csv')\n",
    "    #sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "    topics = topics[topics.id.isin(candidate_df.topic_id.unique())]\n",
    "    used_columns = ['id','title','description']\n",
    "    content = content[used_columns].add_prefix('content_')\n",
    "    topics = topics[used_columns].add_prefix('topic_')\n",
    "    candidate_df = candidate_df.merge(content,how='left',on=['content_id'])\n",
    "    candidate_df = candidate_df.merge(topics,how='left',on=['topic_id'])\n",
    "    del topics,content;gc.collect()\n",
    "    \n",
    "    candidate_df = isna_features(candidate_df,['content_title','content_description','topic_title','topic_description'])\n",
    "    candidate_df = fillna_cols(candidate_df,['content_title','content_description','topic_title','topic_description'])\n",
    "    similarity_cols = ['description','title']\n",
    "    candidate_df = add_distance_features(candidate_df,similarity_cols)\n",
    "    to_drop = ['content_title','content_description','topic_title','topic_description']\n",
    "    candidate_df = candidate_df.drop(to_drop,axis=1)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        groups = candidate_df['topic_id'].values\n",
    "        idxs = candidate_df[['topic_id','content_id']]\n",
    "        y = candidate_df['target']\n",
    "        group_kfold = GroupKFold(n_splits=5)\n",
    "    X = candidate_df.drop(['target','fold','topic_id','content_id'],axis=1)\n",
    "    \n",
    "    if mode == 'val':\n",
    "        y_preds = []\n",
    "        for fold in range(0,len(pca_models)):\n",
    "            X_embeds_small = pca_models[fold].transform(X_embeds)\n",
    "            print(X_embeds_small.shape)\n",
    "            X_test = pd.concat([X.reset_index(drop=True),pd.DataFrame(X_embeds_small,columns=[f\"embed_{i}\" for i in range(1,embed_shape+1)])],axis=1)\n",
    "            y_preds.append(gbdt_models[fold].predict(X_test))\n",
    "    if mode == 'val':\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36c0865f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Shape: (615200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cba4f1264254015889e4db6e1c5d4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211eceb427c541da86c0fd8e6a4f8053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6f4252eca14082bcb9316027d35edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf3f1894a7043af850fd427c971009e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6c71f7e91e4019a9485c2d1719174f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb33dabe3cbe495082a4f5117f510773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████▌                      | 1/2 [00:21<00:21, 21.97s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65896b5d733d45a78acce5d1f6c2422d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b320aa701e294456bed19316b8bff3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f57e06674548a6874f5f2758ffe829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6047d9e9fc7d454da27e5de567ae2db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9925b6fb6a7a40dcb35563d0d9779a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e966b6825dd44d897834a4625733976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=25634), Label(value='0 / 25634')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:36<00:00, 18.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615200, 100)\n",
      "(615200, 100)\n",
      "(615200, 100)\n",
      "(615200, 100)\n",
      "(615200, 100)\n"
     ]
    }
   ],
   "source": [
    "y_predicted = pipeline(mode='val', pca_models=pca_models, gbdt_models=lbg_models, embed_shape=PCA_COMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61a2233a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.494793  , 0.04790724, 0.02105421, ..., 0.00580588, 0.02259164,\n",
       "        0.23737781]),\n",
       " array([0.8488655 , 0.00613431, 0.00511739, ..., 0.00895668, 0.05325166,\n",
       "        0.26633345]),\n",
       " array([0.29296283, 0.02277217, 0.02077438, ..., 0.00659104, 0.02186799,\n",
       "        0.24976229]),\n",
       " array([0.67405427, 0.03341875, 0.01584646, ..., 0.00962327, 0.03666635,\n",
       "        0.36873624]),\n",
       " array([0.57507363, 0.04763113, 0.01370416, ..., 0.02202528, 0.02583454,\n",
       "        0.17136102])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f664c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(np.mean(y_predicted,axis=0)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3510645e",
   "metadata": {},
   "source": [
    "### Kaggle Like Eval Hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "67a7a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/train_top50_fold0_cv_with_groundtruth_final_72044.csv')\n",
    "test = test[test.fold == 0]\n",
    "test['pred_prob'] = np.mean(y_predicted,axis=0)\n",
    "test['pred_binary'] = (np.mean(y_predicted,axis=0)>0.1).astype(int)\n",
    "test = test.sort_values('pred_prob',ascending=False).reset_index(drop=True)\n",
    "gt = pd.read_csv('kfold_correlations.csv')\n",
    "gt = gt[gt.fold == 0]\n",
    "gt.drop('fold',axis=1,inplace=True)\n",
    "gt.content_ids = gt.content_ids.str.split(' ')\n",
    "preds = test[test.pred_binary==1].groupby(['topics_ids'])['content_ids'].agg(list).rename('content_ids_pred').reset_index()\n",
    "no_pos = test[test.pred_binary==0].groupby(['topics_ids']).head(1)\n",
    "no_pos = no_pos[~no_pos.topics_ids.isin(preds.topics_ids)].groupby(['topics_ids'])['content_ids'].agg(list).rename('content_ids_pred').reset_index()\n",
    "preds = pd.concat([preds,no_pos],axis=0)\n",
    "preds.columns = ['topic_id','content_ids_pred']\n",
    "gt = gt.merge(preds,how='left',on='topic_id')\n",
    "gt['content_ids_pred'] = gt['content_ids_pred'].fillna(\"\")\n",
    "gt['correct_pred'] = gt[['content_ids_pred', 'content_ids']].apply(lambda x: len([d for d in x[0] if d in x[1]]), axis=1)\n",
    "gt['precision'] = gt['correct_pred']/(gt['content_ids_pred'].str.len() + 1e-7)\n",
    "gt['recall'] = gt['correct_pred']/(gt['content_ids'].str.len() + 1e-7)\n",
    "for beta in [0.5, 1, 2]:\n",
    "        gt['f'+str(beta)] = ((1 + beta**2) * gt['precision'] * gt['recall'])/((beta**2 * gt['precision']) + gt['recall'] + 1e-7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "655037cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36290432163102154"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.f2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fab4a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 98/98 [04:23<00:00,  2.69s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "thresholds = []\n",
    "scores = []\n",
    "max_score = 0\n",
    "#test = pd.read_csv('data/train_top50_fold0_cv_with_groundtruth_final_72044.csv')\n",
    "#test = test[test.fold == 0]\n",
    "for thres in tqdm(np.arange(0.01, 0.99, 0.01)):\n",
    "    thresholds.append(thres)\n",
    "    #test['pred_prob'] = y_predicted\n",
    "    test = pd.read_csv('data/train_top50_fold0_cv_with_groundtruth_final_72044.csv')\n",
    "    test = test[test.fold == 0]\n",
    "    test['pred_binary'] = (np.mean(y_predicted,axis=0)>thres).astype(int)\n",
    "    #test = test.sort_values('pred_prob',ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    gt = pd.read_csv('kfold_correlations.csv')\n",
    "    gt = gt[gt.fold == 0]\n",
    "    gt.drop('fold',axis=1,inplace=True)\n",
    "    gt.content_ids = gt.content_ids.str.split(' ')\n",
    "    preds = test[test.pred_binary==1].groupby(['topics_ids'])['content_ids'].agg(list).rename('content_ids_pred').reset_index()\n",
    "    #no_pos = test[test.pred_binary==0].groupby(['topics_ids']).head(1)\n",
    "    #no_pos = no_pos[~no_pos.topics_ids.isin(preds.topics_ids)].groupby(['topics_ids'])['content_ids'].agg(list).rename('content_ids_pred').reset_index()\n",
    "    #preds = pd.concat([preds,no_pos],axis=0)\n",
    "    preds.columns = ['topic_id','content_ids_pred']\n",
    "    gt = gt.merge(preds,how='left',on='topic_id')\n",
    "    gt['content_ids_pred'] = gt['content_ids_pred'].fillna(\"\")\n",
    "    gt['correct_pred'] = gt[['content_ids_pred', 'content_ids']].apply(lambda x: len([d for d in x[0] if d in x[1]]), axis=1)\n",
    "    gt['precision'] = gt['correct_pred']/(gt['content_ids_pred'].str.len() + 1e-7)\n",
    "    gt['recall'] = gt['correct_pred']/(gt['content_ids'].str.len() + 1e-7)\n",
    "    for beta in [0.5, 1, 2]:\n",
    "            gt['f'+str(beta)] = ((1 + beta**2) * gt['precision'] * gt['recall'])/((beta**2 * gt['precision']) + gt['recall'] + 1e-7)\n",
    "    score = gt.f2.mean()\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        best_thres = thres\n",
    "    scores.append(gt.f2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f7e701c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11, 0.36219917706614985)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_thres, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4690da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5294696699038235"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6649d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.243137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.274636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.299041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.317746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.331333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.342138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.349593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.355212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.358941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.360733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.362199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.362175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.360661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.358435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.355790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.352247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.348771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.343791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.339240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.333423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.328331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.322665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.316280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.310857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.304429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.298393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.292141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.285808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.279792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.273159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.265716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.259435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.251969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.245823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.239020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.232322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.226114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.219691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.213786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.207032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.200848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.193211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.186907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.180638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.175240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.168692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.162731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.156806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.151157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.145211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.133931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.129278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.124247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.118466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.113872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.108158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.104079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.098754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.093967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.089328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.085624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.081156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.076957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.072718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.069221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.065212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.061481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.058652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.054645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.051159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.048462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.045655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.042280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.039459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.036845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.034577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.031571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.029483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.027360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.025288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.023406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.021527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.019442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.017905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.016369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.014526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.013034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.011473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.010093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.008659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.007201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.006188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.005805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.004686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1\n",
       "0   0.01  0.243137\n",
       "1   0.02  0.274636\n",
       "2   0.03  0.299041\n",
       "3   0.04  0.317746\n",
       "4   0.05  0.331333\n",
       "5   0.06  0.342138\n",
       "6   0.07  0.349593\n",
       "7   0.08  0.355212\n",
       "8   0.09  0.358941\n",
       "9   0.10  0.360733\n",
       "10  0.11  0.362199\n",
       "11  0.12  0.362175\n",
       "12  0.13  0.360661\n",
       "13  0.14  0.358435\n",
       "14  0.15  0.355790\n",
       "15  0.16  0.352247\n",
       "16  0.17  0.348771\n",
       "17  0.18  0.343791\n",
       "18  0.19  0.339240\n",
       "19  0.20  0.333423\n",
       "20  0.21  0.328331\n",
       "21  0.22  0.322665\n",
       "22  0.23  0.316280\n",
       "23  0.24  0.310857\n",
       "24  0.25  0.304429\n",
       "25  0.26  0.298393\n",
       "26  0.27  0.292141\n",
       "27  0.28  0.285808\n",
       "28  0.29  0.279792\n",
       "29  0.30  0.273159\n",
       "30  0.31  0.265716\n",
       "31  0.32  0.259435\n",
       "32  0.33  0.251969\n",
       "33  0.34  0.245823\n",
       "34  0.35  0.239020\n",
       "35  0.36  0.232322\n",
       "36  0.37  0.226114\n",
       "37  0.38  0.219691\n",
       "38  0.39  0.213786\n",
       "39  0.40  0.207032\n",
       "40  0.41  0.200848\n",
       "41  0.42  0.193211\n",
       "42  0.43  0.186907\n",
       "43  0.44  0.180638\n",
       "44  0.45  0.175240\n",
       "45  0.46  0.168692\n",
       "46  0.47  0.162731\n",
       "47  0.48  0.156806\n",
       "48  0.49  0.151157\n",
       "49  0.50  0.145211\n",
       "50  0.51  0.139357\n",
       "51  0.52  0.133931\n",
       "52  0.53  0.129278\n",
       "53  0.54  0.124247\n",
       "54  0.55  0.118466\n",
       "55  0.56  0.113872\n",
       "56  0.57  0.108158\n",
       "57  0.58  0.104079\n",
       "58  0.59  0.098754\n",
       "59  0.60  0.093967\n",
       "60  0.61  0.089328\n",
       "61  0.62  0.085624\n",
       "62  0.63  0.081156\n",
       "63  0.64  0.076957\n",
       "64  0.65  0.072718\n",
       "65  0.66  0.069221\n",
       "66  0.67  0.065212\n",
       "67  0.68  0.061481\n",
       "68  0.69  0.058652\n",
       "69  0.70  0.054645\n",
       "70  0.71  0.051159\n",
       "71  0.72  0.048462\n",
       "72  0.73  0.045655\n",
       "73  0.74  0.042280\n",
       "74  0.75  0.039459\n",
       "75  0.76  0.036845\n",
       "76  0.77  0.034577\n",
       "77  0.78  0.031571\n",
       "78  0.79  0.029483\n",
       "79  0.80  0.027360\n",
       "80  0.81  0.025288\n",
       "81  0.82  0.023406\n",
       "82  0.83  0.021527\n",
       "83  0.84  0.019442\n",
       "84  0.85  0.017905\n",
       "85  0.86  0.016369\n",
       "86  0.87  0.014526\n",
       "87  0.88  0.013034\n",
       "88  0.89  0.011473\n",
       "89  0.90  0.010093\n",
       "90  0.91  0.008659\n",
       "91  0.92  0.007201\n",
       "92  0.93  0.006188\n",
       "93  0.94  0.005805\n",
       "94  0.95  0.004686\n",
       "95  0.96  0.003664\n",
       "96  0.97  0.002313\n",
       "97  0.98  0.001519"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([thresholds,scores]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dbb08c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt['len'] = gt.content_ids_pred.apply(lambda x: len(x))#.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "08554f10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43     53\n",
       "44     55\n",
       "42     59\n",
       "46     61\n",
       "41     64\n",
       "40     64\n",
       "34     71\n",
       "38     75\n",
       "45     77\n",
       "47     77\n",
       "37     79\n",
       "35     79\n",
       "48     80\n",
       "39     81\n",
       "36     82\n",
       "33     91\n",
       "32     97\n",
       "30    113\n",
       "49    119\n",
       "31    119\n",
       "28    120\n",
       "27    134\n",
       "29    140\n",
       "26    146\n",
       "25    159\n",
       "24    162\n",
       "23    188\n",
       "22    188\n",
       "21    228\n",
       "20    240\n",
       "19    247\n",
       "18    268\n",
       "17    339\n",
       "16    352\n",
       "15    358\n",
       "14    375\n",
       "13    399\n",
       "50    413\n",
       "12    414\n",
       "2     453\n",
       "11    496\n",
       "4     500\n",
       "10    505\n",
       "9     512\n",
       "8     523\n",
       "3     547\n",
       "6     549\n",
       "1     573\n",
       "7     576\n",
       "5     604\n",
       "Name: len, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.len.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3cb1808e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PCA(n_components=100, random_state=1),\n",
       " PCA(n_components=100, random_state=1),\n",
       " PCA(n_components=100, random_state=1),\n",
       " PCA(n_components=100, random_state=1),\n",
       " PCA(n_components=100, random_state=1)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d4e36df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from joblib import dump, load\n",
    "for fold in range(0, len(pca_models)):\n",
    "    dump(pca_models[fold], f'pca_{fold}.joblib')\n",
    "    lbg_models[fold].save_model(f'lgb_{fold}.json')\n",
    "    #pk.dump(pca_models[fold], open(f\"models/pca_{fold}.pkl\",\"wb\"))\n",
    "\n",
    "\n",
    "# later reload the pickle file\n",
    "#pca_reload = pk.load(open(\"pca.pkl\",'rb'))\n",
    "#result_new = pca_reload .transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
